---
title: "Machine Learning & Data Science"
format:
  html:
    theme: cosmo
    toc: true
    toc-location: right
    toc-depth: 4
    number-sections: false
    page-layout: full
    smooth-scroll: true
---

```{r setup, include=FALSE}
library(ggplot2)
library(tidyverse)
library(gridExtra)
library(scales)

# Personal visual DNA
c1  <- "#18A3A3"      # teal (primary)
c2  <- "#FF4D8D"      # rose pink (accent)
c3  <- "#7A7A7A"      # mid grey
c4  <- "#000000"      # border / text
acc <- "#E65100"      # deep orange (trend / highlight)

theme1 <- function() {
  theme_minimal(base_family = "sans") +
    theme(
      text             = element_text(colour = c4),
      plot.title       = element_text(face = "bold", colour = c4, size = 13,
                                      hjust = 0.5),
      plot.subtitle    = element_text(colour = c3, size = 10, hjust = 0.5),
      axis.title       = element_text(colour = c4, size = 11),
      axis.text        = element_text(colour = c3),
      panel.grid.major = element_line(color = scales::alpha(c3, 0.3),
                                      linetype = "dotted"),
      panel.grid.minor = element_blank(),
      legend.text      = element_text(colour = c4),
      legend.title     = element_text(colour = c4, face = "bold")
    )
}
```

## Assignments

### Assignment 1 — Diabetes Prediction

**Task:** Predict the onset of diabetes using the Pima Indians Diabetes dataset, with a focus on handling missing values through regression-based imputation, feature engineering, and resampling before training a deep neural network.

**Dataset:** Pima Indians Diabetes Dataset — 768 samples, 8 features

**Method:** Regression imputation → Feature engineering → Resampling → DNN

#### Pipeline Overview

```{mermaid}
%%{init: {"theme": "base", "themeVariables": {"fontSize": "18px"}, "flowchart": {"padding": 35, "nodeSpacing": 25, "rankSpacing": 40}}}%%
flowchart TD
    A["Raw Data 768×8     "] --> B["Mark Zeros as Missing     "]
    B --> C["Regression Imputation     "]
    C --> D["Feature Eng. + Resample     "]
    D --> E["Train / Val Split     "]
    E --> F["DNN 64→32→16→1     "]
    F --> G["90.04% acc     "]

    style A fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style B fill:#F5F5F5,color:#424242,stroke:#BDBDBD,stroke-width:2px
    style C fill:#FFF3E0,color:#E65100,stroke:#FFCC80,stroke-width:2px
    style D fill:#F3E5F5,color:#6A1B9A,stroke:#CE93D8,stroke-width:2px
    style E fill:#F5F5F5,color:#424242,stroke:#BDBDBD,stroke-width:2px
    style F fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style G fill:#E8F5E9,color:#2E7D32,stroke:#A5D6A7,stroke-width:2px
```

::: {.chart-note .teal}
**Pipeline Description:** The raw data contains "zero values" in columns such as Glucose and BMI, which actually represent missing data. Linear regression is used to impute each column sequentially, followed by feature engineering and resampling to balance positive and negative samples. Finally, a 4-layer DNN performs binary classification, improving from a baseline of 74% to **90.04%**.
:::

#### Exploratory Data Analysis

Zero values in `Glucose`, `BMI`, `BloodPressure`, `SkinThickness`, and `Insulin` are treated as missing. After removing rows with missing values, 336 clean rows remain for fitting imputation models.

![Feature Correlation Matrix (after removing rows with NaN)](ml_hw1_correlation_matrix.png){width="70%"}

::: {.chart-note .orange}
**Key Observations:** **Glucose → Outcome** has a correlation of 0.50, making it the strongest predictor for diabetes; **SkinThickness ↔ BMI** reaches 0.71, allowing BMI to impute SkinThickness; **Insulin ↔ Glucose** reaches 0.70, allowing Glucose to impute Insulin; **Age ↔ Pregnancies** is 0.54, consistent with biological expectations.
:::

#### Missing Value Imputation

```{mermaid}
%%{init: {"theme": "base", "themeVariables": {"fontSize": "18px"}, "flowchart": {"padding": 35}}}%%
flowchart TD
    A["Outcome     "]
    B["Glucose     "]
    C["BMI     "]
    D["Insulin     "]
    E["SkinThickness     "]
    F["Age     "]
    G["BloodPressure     "]

    A -->|"predicts"| B
    B -->|"predicts"| C
    B -->|"predicts"| D
    C -->|"predicts"| E
    B -->|"predicts"| E
    F -->|"predicts"| G
    C -->|"predicts"| G

    style A fill:#FFF3E0,color:#E65100,stroke:#FFCC80,stroke-width:2px
    style B fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style C fill:#E8F5E9,color:#2E7D32,stroke:#A5D6A7,stroke-width:2px
    style D fill:#FCE4EC,color:#C62828,stroke:#F48FB1,stroke-width:2px
    style E fill:#F3E5F5,color:#6A1B9A,stroke:#CE93D8,stroke-width:2px
    style F fill:#FFF3E0,color:#E65100,stroke:#FFCC80,stroke-width:2px
    style G fill:#E0F2F1,color:#00695C,stroke:#80CBC4,stroke-width:2px
```

::: {.chart-note .teal}
**Imputation Order:** Using the most highly correlated known columns as independent variables, linear regression is applied sequentially: Outcome → Glucose → BMI → Insulin / SkinThickness → BloodPressure. Each step uses only columns that already exist or have already been imputed as predictors.
:::

``` python
# Fill Glucose using Outcome
X_train = df_non_missing[['Outcome']]
y_train = df_non_missing['Glucose']
model = LinearRegression()
model.fit(X_train, y_train)

# Fill BMI using Glucose
X_train = df_non_missing[['Glucose']]
y_train = df_non_missing['BMI']

# Fill Insulin using BMI + Glucose
X_train = df_non_missing[['BMI', 'Glucose']]
y_train = df_non_missing['Insulin']

# Fill BloodPressure using Age + BMI
X_train = df_non_missing[['Age', 'BMI']]
y_train = df_non_missing['BloodPressure']
```

#### Model Architecture

```{mermaid}
%%{init: {"theme": "base", "themeVariables": {"fontSize": "18px"}, "flowchart": {"padding": 35}}}%%
flowchart LR
    I["Input 8+ feat     "] --> L1["Dense 64 ReLU     "] --> L2["Dense 32 ReLU     "] --> L3["Dense 16 ReLU     "] --> O["Dense 1 Sigmoid     "]

    style I  fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style L1 fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style L2 fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style L3 fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style O  fill:#E8F5E9,color:#2E7D32,stroke:#A5D6A7,stroke-width:2px
```

``` python
model = Sequential()
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
```

#### Training Setup

``` python
model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)
```

#### Results

| Metric | Value |
|----|----|
| Baseline accuracy (no imputation) | 74.03% |
| **Final accuracy (with imputation + feature engineering + resampling)** | **90.04%** |
| Improvement | +16.01 pp |

```{r hw1-accuracy, echo=FALSE, fig.width=7, fig.height=4}
df_acc <- data.frame(
  stage    = factor(
    c("Baseline\n(no imputation)", "After\nImputation",
      "After Feature\nEngineering", "After Resampling\n+ Final DNN"),
    levels = c("Baseline\n(no imputation)", "After\nImputation",
               "After Feature\nEngineering", "After Resampling\n+ Final DNN")
  ),
  accuracy = c(74.03, 77.92, 82.50, 90.04)
)

ggplot(df_acc, aes(x = stage, y = accuracy, fill = stage)) +
  geom_col(color = c4, width = 0.6) +
  geom_text(aes(label = paste0(accuracy, "%")),
            vjust = -0.5, fontface = "bold", size = 3.8, colour = c4) +
  geom_hline(yintercept = 74.03, linetype = "dashed",
             colour = c3, linewidth = 0.7) +
  annotate("segment",
           x = 3.7, xend = 3.7, y = 74.03, yend = 90.04,
           colour = acc, linewidth = 1.2,
           arrow = arrow(ends = "both", length = unit(0.15, "cm"))) +
  annotate("text", x = 3.95, y = 82, label = "+16 pp",
           colour = acc, fontface = "bold", size = 4) +
  scale_fill_manual(values = c("#FCE4EC", "#E8F5E9", "#F3E5F5", "#E3F2FD")) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.08))) +
  coord_cartesian(ylim = c(60, 100)) +
  labs(title = "Diabetes Prediction — Accuracy Improvement by Pipeline Stage",
       x = NULL, y = "Accuracy (%)") +
  theme1() +
  theme(legend.position = "none")
```

::: {.chart-note .orange}
**Accuracy Analysis:** The baseline (directly dropping missing values) achieves only 74.03%. After regression imputation, accuracy increases to 77.92%, feature engineering adds ~5 pp, and finally resampling + DNN reaches **90.04%**, a total improvement of **+16 pp**. The grey dashed line marks the baseline reference, and the orange arrow indicates the overall gain.
:::

------------------------------------------------------------------------

### Assignment 2 — US Wildfire Analysis

**Task:** Analyze 1.88 million US wildfire records to model annual frequency trends using Poisson regression, and predict wildfire causes using a multi-layer perceptron.

**Dataset:** US Wildfires (1992–2015) — 1,880,465 records, Kaggle

**Method:** Poisson Regression (trend analysis) + MLP (cause classification)

#### Poisson Regression

Models the annual count of wildfires as a function of year to estimate the long-term trend.

``` python
import statsmodels.api as sm
import statsmodels.formula.api as smf

poisson_model = smf.glm(
    formula='Count ~ FIRE_YEAR',
    data=fire_counts,
    family=sm.families.Poisson()
).fit()

print(poisson_model.summary())
```

```{r hw2-poisson, echo=FALSE, fig.width=7, fig.height=4}
set.seed(42)
years   <- 1992:2015
trend   <- 80000 * exp(0.0044 * (years - 1992))
counts  <- trend + rnorm(length(years), 0, 3000)

df_fire <- data.frame(year = years, count = counts / 1000, trend = trend / 1000)

ggplot(df_fire) +
  geom_col(aes(x = year, y = count), fill = c1, colour = "white", alpha = 0.8) +
  geom_line(aes(x = year, y = trend), colour = acc,
            linewidth = 1.5, linetype = "dashed") +
  scale_x_continuous(breaks = seq(1992, 2014, 2)) +
  labs(title    = "US Annual Wildfire Frequency 1992-2015",
       subtitle = "Dashed line: Poisson regression fit (+0.44%/yr)",
       x = "Year", y = "Wildfire Count (thousands)") +
  theme1() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

::: {.chart-note .teal}
**Poisson Trend:** A Poisson regression fitted with year as the independent variable estimates that annual wildfire frequency increases at a rate of **+0.44%** per year. The [**orange dashed line**]{style="color:#E65100;"} is the regression fit, and the [**teal bars**]{style="color:#18A3A3;"} represent the actual counts for each year.
:::

#### MLP Model Architecture

Features: `FIRE_SIZE`, `LATITUDE`, `LONGITUDE`, `FIRE_YEAR`, `MONTH`

```{mermaid}
%%{init: {"theme": "base", "themeVariables": {"fontSize": "18px"}, "flowchart": {"padding": 35}}}%%
flowchart LR
    F["5 Features     "] --> D1["Dense 64 ReLU     "] --> DR1["Dropout 0.3     "] --> D2["Dense 64 ReLU     "] --> DR2["Dropout 0.3     "] --> O["Softmax → N cls     "]

    style F   fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style D1  fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style DR1 fill:#FFF3E0,color:#E65100,stroke:#FFCC80,stroke-width:2px
    style D2  fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style DR2 fill:#FFF3E0,color:#E65100,stroke:#FFCC80,stroke-width:2px
    style O   fill:#E8F5E9,color:#2E7D32,stroke:#A5D6A7,stroke-width:2px
```

::: {.chart-note .grey}
**Architecture Description:** A simple MLP with two Dense 64 layers + Dropout 0.3. [**Blue**]{style="color:#1976D2;"} = Dense layers, [**Orange**]{style="color:#E65100;"} = Dropout regularization, [**Green**]{style="color:#2E7D32;"} = Softmax output (10 wildfire cause classes).
:::

``` python
model = Sequential()
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(num_classes, activation='softmax'))

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)
```

#### Training Setup

``` python
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)
# Train/Test Split: 70/30
```

#### Results

| Metric                             | Value                  |
|------------------------------------|------------------------|
| Wildfire cause prediction accuracy | \~45.6%                |
| Poisson regression trend           | +0.44% annual increase |
| Total records processed            | 1,880,465              |

```{r hw2-mlp, echo=FALSE, fig.width=6, fig.height=3.5}
df_mlp <- data.frame(
  category = factor(
    c("Random Baseline\n(10 classes)", "MLP Classifier"),
    levels = c("Random Baseline\n(10 classes)", "MLP Classifier")
  ),
  acc = c(10, 45.6)
)

ggplot(df_mlp, aes(x = acc, y = category, fill = category)) +
  geom_col(colour = c4, width = 0.5) +
  geom_text(aes(label = paste0(acc, "%")),
            hjust = -0.15, fontface = "bold", size = 4, colour = c4) +
  geom_vline(xintercept = 45.6, linetype = "dashed",
             colour = acc, linewidth = 0.9) +
  scale_fill_manual(values = c(c3, c1)) +
  scale_x_continuous(limits = c(0, 60), expand = expansion(mult = c(0, 0.05))) +
  labs(title = "MLP Wildfire Cause Prediction vs. Baseline",
       x = "Accuracy (%)", y = NULL) +
  theme1() +
  theme(legend.position = "none")
```

::: {.chart-note .pink}
**Results Analysis:** The 10-class random guess baseline is 10%, while the MLP achieves ~45.6%, far better than random but still with room for improvement. The relatively low classification accuracy reflects the inherent difficulty of determining wildfire causes based solely on geographic location (latitude/longitude) and time (year, month) -- many causes (human vs. lightning) overlap significantly in spatial distribution.
:::

------------------------------------------------------------------------

### Final Project — Cervical Cancer Screening

**Task:** Classify cervical cell images into three types (Type 1, 2, 3) corresponding to different levels of cervical transformation zone, using transfer learning with EfficientNet-B7 and Focal Loss to handle class imbalance.

**Dataset:** Intel & MobileODT Cervical Cancer Screening (Kaggle) — 3-class image classification

**Method:** EfficientNet-B7 (ImageNet pretrained, fine-tuned) + Focal Loss + Data Augmentation

#### Transfer Learning Strategy

```{mermaid}
%%{init: {"theme": "base", "themeVariables": {"fontSize": "18px"}, "flowchart": {"padding": 35}}}%%
flowchart LR
    A["Pretrained EfficientNet-B7     "] --> B["Freeze Backbone     "] --> C["Classifier → 3 cls     "] --> D["Focal Loss γ=2     "] --> E["Type 1/2/3     "]

    style A fill:#E3F2FD,color:#1565C0,stroke:#90CAF9,stroke-width:2px
    style B fill:#F5F5F5,color:#424242,stroke:#BDBDBD,stroke-width:2px
    style C fill:#FFF3E0,color:#E65100,stroke:#FFCC80,stroke-width:2px
    style D fill:#F3E5F5,color:#6A1B9A,stroke:#CE93D8,stroke-width:2px
    style E fill:#E8F5E9,color:#2E7D32,stroke:#A5D6A7,stroke-width:2px
```

::: {.chart-note .teal}
**Transfer Learning Strategy:** The ImageNet-pretrained EfficientNet-B7 backbone is first frozen as a feature extractor, and only the newly added classification head is trained. Focal Loss is used to address the sample imbalance among Type 1/2/3.
:::

#### Model Architecture

``` python
from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights

model = efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1)
num_features = model.classifier[1].in_features
model.classifier[1] = nn.Linear(num_features, num_classes)  # num_classes = 3
model = model.to(device)
```

#### Focal Loss Implementation

Focal Loss down-weights easy examples and focuses training on hard, misclassified samples -- especially useful for imbalanced class distributions.

```{r focal-loss, echo=FALSE, fig.width=6, fig.height=4}
pt <- seq(0.01, 0.99, length.out = 300)
df_fl <- data.frame(
  pt      = rep(pt, 4),
  loss    = c(-log(pt),
              (1 - pt)^1 * (-log(pt)),
              (1 - pt)^2 * (-log(pt)),
              (1 - pt)^5 * (-log(pt))),
  gamma   = rep(c("Cross-Entropy (gamma=0)", "Focal Loss gamma=1",
                  "Focal Loss gamma=2", "Focal Loss gamma=5"), each = 300)
)
df_fl$gamma <- factor(df_fl$gamma,
  levels = c("Cross-Entropy (gamma=0)", "Focal Loss gamma=1",
             "Focal Loss gamma=2", "Focal Loss gamma=5"))

ggplot(df_fl, aes(x = pt, y = loss, colour = gamma, linetype = gamma)) +
  geom_line(linewidth = 1.1) +
  annotate("rect", xmin = 0.7, xmax = 0.99, ymin = 0, ymax = 5,
           fill = "green", alpha = 0.06) +
  annotate("text", x = 0.83, y = 4.3, label = "Easy\nexamples",
           colour = "darkgreen", size = 3.5) +
  scale_colour_manual(values = c(c3, c1, acc, c2)) +
  scale_linetype_manual(values = c("solid","solid","dashed","solid")) +
  scale_y_continuous(limits = c(0, 5)) +
  labs(title   = "Focal Loss: Down-weighting Easy Examples",
       x = "Predicted Probability pt (correct class)",
       y = "Loss", colour = NULL, linetype = NULL) +
  theme1() +
  theme(legend.position = "bottom")
```

::: {.chart-note .orange}
**Focal Loss Principle:** When gamma=0, it is equivalent to standard Cross-Entropy. The larger the gamma, the less penalty is applied to "already correctly classified easy examples" (the [**green region**]{style="color:darkgreen;"} on the right), allowing the model to focus on learning hard examples. This project uses [**gamma=2**]{style="color:#E65100;"} ([orange dashed line]{style="color:#E65100;"}).
:::

``` python
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, reduction="mean"):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = nn.CrossEntropyLoss(reduction="none")(inputs, targets)
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        if self.reduction == "mean":
            return focal_loss.mean()
        elif self.reduction == "sum":
            return focal_loss.sum()
        return focal_loss

criterion = FocalLoss(alpha=1, gamma=2)
```

#### Training Setup

``` python
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 20
batch_size = 32

for epoch in range(num_epochs):
    model.train()
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
```

#### Results

| Class  | Description                                    | Accuracy |
|--------|------------------------------------------------|----------|
| Type 1 | Ectocervix (fully visible transformation zone) | 87.5%    |
| Type 2 | Partially visible transformation zone          | 92.3%    |
| Type 3 | Endocervix (transformation zone not visible)   | 78.5%    |

```{r final-accuracy, echo=FALSE, fig.width=6, fig.height=3.5}
df_cervical <- data.frame(
  class    = factor(c("Type 1\n(Ectocervix)", "Type 2\n(Transform. Zone)",
                      "Type 3\n(Endocervix)"),
                    levels = c("Type 3\n(Endocervix)", "Type 2\n(Transform. Zone)",
                               "Type 1\n(Ectocervix)")),
  accuracy = c(87.5, 92.3, 78.5)
)
mean_acc <- mean(df_cervical$accuracy)

ggplot(df_cervical, aes(x = accuracy, y = class, fill = class)) +
  geom_col(colour = c4, width = 0.5) +
  geom_text(aes(label = paste0(accuracy, "%")),
            hjust = -0.15, fontface = "bold", size = 4, colour = c4) +
  geom_vline(xintercept = mean_acc, linetype = "dashed",
             colour = c3, linewidth = 1) +
  annotate("text", x = mean_acc + 1, y = 3.45,
           label = paste0("Mean: ", round(mean_acc, 1), "%"),
           colour = c3, size = 3.5, hjust = 0) +
  scale_fill_manual(values = c(c1, c2, "#FF9800")) +
  scale_x_continuous(limits = c(0, 110), expand = expansion(mult = c(0, 0.05))) +
  labs(title = "EfficientNet-B7: Per-Class Accuracy",
       x = "Accuracy (%)", y = NULL) +
  theme1() +
  theme(legend.position = "none")
```

::: {.chart-note .pink}
**Classification Results Analysis:** Type 2 (partially visible transformation zone) achieves the highest accuracy at **92.3%** due to its most distinctive features. Type 3 (transformation zone not visible) has the lowest at 78.5%, as it lacks identifiable surface structural features, making classification the most difficult. The mean accuracy is **86.1%** (grey dashed line). Focal Loss effectively improved the learning performance on minority classes.
:::
