[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is a working portfolio and notebook.\nIt documents selected projects, visual studies, and experiments as they evolve.\nNot all content represents final results. Some materials are exploratory or incomplete."
  },
  {
    "objectID": "EPPS6356.html",
    "href": "EPPS6356.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Assignment 1\n\n\n\nAssignment 2\n\n\n\nAssignment 3\n\n\n\n\ndata(iris)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# 1. Divide the dataset into three rectangles based on species.\n# The average of Petal.Length and Petal.Width is the length and width.\n# Draw three rectangles arranged horizontally.\n\n#1\n\nplot_data &lt;- iris %&gt;%\n  mutate(\n    sepal_length_group = cut(\n      Sepal.Length,\n      breaks = c(4, 5.5, 7.0, 8.0),\n      labels = c(\"Small (4.0-5.5)\", \"Medium (5.6-7.0)\", \"Large (7.1-8.0)\"),\n      include.lowest = TRUE\n    )\n  ) %&gt;%\n  group_by(sepal_length_group) %&gt;%\n  summarise(\n    count = n(),\n    avg_petal_length = mean(Petal.Length)\n  ) %&gt;%\n  mutate(\n    xmax = cumsum(count),\n    xmin = xmax - count,\n    x_label_pos = (xmin + xmax) / 2\n  )\n\nggplot(plot_data, aes(ymin = 0)) +\n  geom_rect(\n    aes(\n      xmin = xmin,\n      xmax = xmax,\n      ymax = avg_petal_length,\n      fill = sepal_length_group\n    ),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    breaks = plot_data$x_label_pos,\n    labels = plot_data$sepal_length_group,\n    expand = c(0, 0)\n  ) +\n  scale_fill_viridis_d(option = \"D\", direction = -1) +\n  labs(\n    title = \"Average Petal Length by Sepal Length Group\",\n    subtitle = \"Column width is proportional to the number of flowers in each group\",\n    x = \"Count of Flowers in Group\",\n    y = \"Average Petal Length (cm)\",\n    fill = \"Sepal Length Group\"\n  ) +\n  # Apply a clean theme\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 18),\n    legend.position = \"bottom\",\n    panel.grid.major.x = element_blank(), # Remove vertical grid lines\n    panel.grid.minor.x = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n# 2. table with embedded charts\niris_long &lt;- iris %&gt;%\n  pivot_longer(cols = -Species, names_to = \"Measurement\", values_to = \"Value\")\n\nggplot(iris_long, aes(x = Value, fill = Species)) +\n  geom_histogram(color = \"white\", bins = 15) +\n  facet_grid(Species ~ Measurement, scales = \"free\") +\n  scale_fill_manual( #coloring each species\n    values = c(\n      \"setosa\" = \"steelblue\", \n      \"versicolor\" = \"orange\",   \n      \"virginica\" = \"seagreen\"     \n    ) \n    ) + #labels\n      labs(\n        title = \"Distribution of Iris Measurements by Species\",\n        x = \"Measurement Value (cm)\",\n        y = \"Count\"\n      ) +\n  theme_bw() +\n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\"),\n      strip.text.x = element_text(face = \"bold\"),\n      strip.text.y = element_text(face = \"bold\"),\n      panel.border = element_rect(color = \"grey80\", fill = NA),\n      legend.position = \"bottom\"\n    )\n\n\n\n\n\n\n\n\n\n# 3. Extract setona and versicolor from species.\n# Then create df_2 and df_3. Draw a bar plot using petal.width: p1 p2.\n# Finally, use gridExtra to combine the plots.'\nlibrary(\"gridExtra\")\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\ndf_2 &lt;- subset(iris, Species %in% \"setosa\")\ndf_3 &lt;- subset(iris, Species %in% \"versicolor\")\ndf_2$id &lt;- 1:nrow(df_2)\ndf_3$id &lt;- 1:nrow(df_3)\n\n\n\np1 = ggplot(df_2, aes(x = factor(id), y = Petal.Width)) +\n  geom_bar(stat = \"identity\", fill = 'red', color = \"black\") +\n  coord_flip() +\n  labs(title = \"setosa\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank() #this was by GPT\n  )\n\n\np2 = ggplot(df_3, aes(x = factor(id), y = Petal.Width)) +\n  geom_bar(stat = \"identity\", fill = \"blue\", color = \"black\") +\n  coord_flip() +\n  labs(title = \"versicolor\")+\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank() #this was by GPT\n  )\n\n\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\n# 4 Column Chart\n# getting means of Petal length and width for each species\n# and mean sepal length and sepal width\niris_means &lt;- iris %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    mean_sepal_length = mean(Sepal.Length),\n    mean_sepal_width = mean(Sepal.Width),\n    mean_petal_length = mean(Petal.Length),\n    mean_petal_width = mean(Petal.Width)\n  ) %&gt;%\n  pivot_longer(\n    cols = -Species,\n    names_to = \"Measurement\",\n    values_to = \"MeanValue\"\n    )\n\nggplot(iris_means, aes(x = Measurement, y = MeanValue, fill = Species)) +\n  geom_col(position = position_dodge(width = 0.8)) + \n  labs(title = \"Mean Iris Measurements by Species\",\n       x = \"Measurement\", y = \"Mean Value\") + \n  theme_minimal(base_size = 12) +\n  scale_fill_manual(values = c(\"steelblue\", \"orange\", \"seagreen\"))\n\n\n\n\n\n\n\n\n\nClass coding competition\n\n\nlibrary(ggplot2)\nmpg &lt;- as.data.frame(mpg)\n#2seater, compact, midsize, minivan, pickup, subcompact, suv scatterplots in one view\nggplot(mpg, aes(x=displ, y=hwy)) +\n  geom_point(color = \"black\") +\n  facet_wrap(~ class) +\n  labs(x=\"displ\",\n       y=\"hwy\") +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n#improving the chart\nggplot(mpg, aes(x=displ, y=hwy)) +\n  geom_point(color = \"blue\", size=2, alpha=0.3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#E65100\", linewidth = 0.8) +\n  facet_wrap(~ class) +\n  labs(title=\"Engine Displacement vs Highway MPG by Vehicle Class\",\n       x=\"Engine Displacement (liters)\",\n       y=\"Highway Miles per Gallon (MPG)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size=16, face=\"bold\"),\n    axis.title.x = element_text(size=12),\n    axis.title.y = element_text(size=12)\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n# GPT was used for picking colors and family.\n# GPT was used for adjusting the format of the code.\nlibrary(ggplot2)\nlibrary(scales)   # for alpha()\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\ndata(iris)\ncolor1 &lt;- \"#18A3A380\"\ncolor2 &lt;- \"#FF4D8DCC\"\ncolor3 &lt;- \"#7A7A7A\"\ncolor4 &lt;- \"#000000\"\nbase_family &lt;- \"sans\"\n\n# custom theme used across plots\ntheme1 &lt;- function() {\n  theme_minimal(base_family = base_family) +\n    theme(\n      text        = element_text(family = base_family, colour = color4),\n      plot.title  = element_text(face = \"bold\", colour = color4, size = 13),\n      axis.title  = element_text(colour = color4),\n      axis.text   = element_text(colour = color3),\n      panel.grid.major = element_line(color = scales::alpha(color3, 0.3), linetype = \"dotted\"),\n      panel.grid.minor = element_blank()\n    )\n}\n\n\nHisto &lt;- function(){\n  hist(iris$Sepal.Length,\n       main=\"Distribution of Sepal Length (iris)\",\n       col=color1, border=color3)\n}\n\nBar1 &lt;- function(){\n  barplot(table(iris$Species),\n          col=c(color1,color2,color3),\n          border=color4,\n          main=\"Count by Species\",\n          xlab=\"Species\", ylab=\"Count\")\n}\n\nBar2 &lt;- function(){\n  barplot(table(iris$Species),\n          horiz=TRUE,\n          col=c(color1,color2,color3),\n          border=color4,\n          main=\"Count by Species (Horizontal)\",\n          xlab=\"Count\", ylab=\"Species\")\n}\n\nPie &lt;- function(){\n  pie(table(iris$Species),\n      col=c(color1,color2,color3),\n      main=\"Species Composition\",\n      clockwise=TRUE)\n}\n\nBox &lt;- function(){\n  boxplot(Sepal.Length~Species, data=iris,\n          col=c(color1,color2,color3),\n          main=\"Sepal Length by Species\",\n          xlab=\"Species\", ylab=\"Sepal Length (cm)\")\n}\n\nScat &lt;- function(){\n  plot(iris$Petal.Length, iris$Sepal.Length,\n       main=\"Sepal vs Petal Length\",\n       xlab=\"Petal Length (cm)\", ylab=\"Sepal Length (cm)\",\n       pch=19, col=color1)\n}\n\n\nlibrary(gridExtra)\n\npar(mfrow=c(2,3), mar=c(4,4,2.5,1), family=\"sans\")\nHisto(); Bar1(); Bar2(); Pie(); Box(); Scat()\n\n\n\n\n\n\n\n\n\ndraw6 &lt;- function(){\n  par(mfrow=c(2,3), mar=c(4,4,2.5,1), family=base_family)\n  Histo(); Bar1(); Bar2(); Pie(); Box(); Scat()\n}\n\nsave_plot &lt;- function(fmt, file){\n  switch(fmt,\n    pdf  = pdf(file, width=10, height=7, family=base_family),\n    jpg  = jpeg(file, width=2400, height=1600, res=300, quality=95),\n    svg  = svg(file, width=2400, height=1600),\n    tiff = tiff(file, width=2400, height=1600, res=300),\n    bmp  = bmp(file, width=2400, height=1600, res=300), # cannot find bmg, and was told it might be .bmp by GPT\n  )\n  draw6(); invisible(dev.off())\n}\n\n\nsave_plot(\"pdf\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.pdf\")\nsave_plot(\"jpg\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.jpg\")\nsave_plot(\"svg\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.svg\")\nsave_plot(\"tiff\", \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.tiff\")\nsave_plot(\"bmp\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.bmp\")\n\nPDF of base R plots\nJPG of base R plots\nSVG of base R plots\nTIFF of base R plots\nBMP of base R plots\n\nggHisto &lt;- ggplot(iris, aes(x=Sepal.Length)) +\n  geom_histogram(fill=color1, color=color3, bins=20) +\n  labs(title=\"Distribution of Sepal Length (iris)\") +\n  theme1()\n\nggBar1 &lt;- ggplot(iris, aes(x=Species, fill=Species)) +\n  geom_bar(color=color4) +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Count by Species\") +\n  theme1() + ggplot2::theme(legend.position=\"none\")\n\nggBar2 &lt;- ggplot(iris, aes(x=Species, fill=Species)) +\n  geom_bar(color=color4) + coord_flip() +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Count by Species (Horizontal)\") +\n  theme1() + ggplot2::theme(legend.position=\"none\")\n\ndf &lt;- as.data.frame(prop.table(table(iris$Species)))\ncolnames(df) &lt;- c(\"Species\",\"prop\")\nggPie &lt;- ggplot(df, aes(x=\"\", y=prop, fill=Species)) +\n  geom_col(width=1, color=NA) + coord_polar(theta=\"y\") +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Species Composition\") +\n  theme1() + ggplot2::theme(axis.text=ggplot2::element_blank(),\n                            axis.title=ggplot2::element_blank(),\n                            panel.grid=ggplot2::element_blank(),\n                            legend.position=\"right\")\n\nggBox &lt;- ggplot(iris, aes(x=Species, y=Sepal.Length, fill=Species)) +\n  geom_boxplot(color=color4) +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Sepal Length by Species\") +\n  theme1() + ggplot2::theme(legend.position=\"none\")\n\nggScat &lt;- ggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point(color=color1, size=2) +\n  labs(title=\"Sepal vs Petal Length\") +\n  theme1()\n\n\ngridExtra::grid.arrange(ggHisto, ggBar1, ggBar2, ggPie, ggBox, ggScat, ncol = 3)\n\n\n\n\n\n\n\n\n\ncombo &lt;- gridExtra::arrangeGrob(ggHisto, ggBar1, ggBar2, ggPie, ggBox, ggScat, ncol = 3)\noutdir &lt;- \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io\"\nformats &lt;- c(\"pdf\", \"jpg\", \"svg\", \"tiff\", \"bmp\")\n\nfor (fmt in formats) {\n  outpath &lt;- file.path(outdir, paste0(\"ggplot_6plots.\", fmt))\n  ggplot2::ggsave(\n    filename = outpath,\n    plot = combo,\n    width = 10, height = 7, dpi = 300\n  )\n}\n\nPDF of ggplot2 plots\nJPG of ggplot2 plots\nSVG of ggplot2 plots\nTIFF of ggplot2 plots\nBMP of ggplot2 plots"
  },
  {
    "objectID": "EPPS6356.html#assignments",
    "href": "EPPS6356.html#assignments",
    "title": "Data Visualization",
    "section": "",
    "text": "Assignment 1\n\n\n\nAssignment 2\n\n\n\nAssignment 3\n\n\n\n\ndata(iris)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# 1. Divide the dataset into three rectangles based on species.\n# The average of Petal.Length and Petal.Width is the length and width.\n# Draw three rectangles arranged horizontally.\n\n#1\n\nplot_data &lt;- iris %&gt;%\n  mutate(\n    sepal_length_group = cut(\n      Sepal.Length,\n      breaks = c(4, 5.5, 7.0, 8.0),\n      labels = c(\"Small (4.0-5.5)\", \"Medium (5.6-7.0)\", \"Large (7.1-8.0)\"),\n      include.lowest = TRUE\n    )\n  ) %&gt;%\n  group_by(sepal_length_group) %&gt;%\n  summarise(\n    count = n(),\n    avg_petal_length = mean(Petal.Length)\n  ) %&gt;%\n  mutate(\n    xmax = cumsum(count),\n    xmin = xmax - count,\n    x_label_pos = (xmin + xmax) / 2\n  )\n\nggplot(plot_data, aes(ymin = 0)) +\n  geom_rect(\n    aes(\n      xmin = xmin,\n      xmax = xmax,\n      ymax = avg_petal_length,\n      fill = sepal_length_group\n    ),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    breaks = plot_data$x_label_pos,\n    labels = plot_data$sepal_length_group,\n    expand = c(0, 0)\n  ) +\n  scale_fill_viridis_d(option = \"D\", direction = -1) +\n  labs(\n    title = \"Average Petal Length by Sepal Length Group\",\n    subtitle = \"Column width is proportional to the number of flowers in each group\",\n    x = \"Count of Flowers in Group\",\n    y = \"Average Petal Length (cm)\",\n    fill = \"Sepal Length Group\"\n  ) +\n  # Apply a clean theme\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 18),\n    legend.position = \"bottom\",\n    panel.grid.major.x = element_blank(), # Remove vertical grid lines\n    panel.grid.minor.x = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n# 2. table with embedded charts\niris_long &lt;- iris %&gt;%\n  pivot_longer(cols = -Species, names_to = \"Measurement\", values_to = \"Value\")\n\nggplot(iris_long, aes(x = Value, fill = Species)) +\n  geom_histogram(color = \"white\", bins = 15) +\n  facet_grid(Species ~ Measurement, scales = \"free\") +\n  scale_fill_manual( #coloring each species\n    values = c(\n      \"setosa\" = \"steelblue\", \n      \"versicolor\" = \"orange\",   \n      \"virginica\" = \"seagreen\"     \n    ) \n    ) + #labels\n      labs(\n        title = \"Distribution of Iris Measurements by Species\",\n        x = \"Measurement Value (cm)\",\n        y = \"Count\"\n      ) +\n  theme_bw() +\n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\"),\n      strip.text.x = element_text(face = \"bold\"),\n      strip.text.y = element_text(face = \"bold\"),\n      panel.border = element_rect(color = \"grey80\", fill = NA),\n      legend.position = \"bottom\"\n    )\n\n\n\n\n\n\n\n\n\n# 3. Extract setona and versicolor from species.\n# Then create df_2 and df_3. Draw a bar plot using petal.width: p1 p2.\n# Finally, use gridExtra to combine the plots.'\nlibrary(\"gridExtra\")\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\ndf_2 &lt;- subset(iris, Species %in% \"setosa\")\ndf_3 &lt;- subset(iris, Species %in% \"versicolor\")\ndf_2$id &lt;- 1:nrow(df_2)\ndf_3$id &lt;- 1:nrow(df_3)\n\n\n\np1 = ggplot(df_2, aes(x = factor(id), y = Petal.Width)) +\n  geom_bar(stat = \"identity\", fill = 'red', color = \"black\") +\n  coord_flip() +\n  labs(title = \"setosa\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank() #this was by GPT\n  )\n\n\np2 = ggplot(df_3, aes(x = factor(id), y = Petal.Width)) +\n  geom_bar(stat = \"identity\", fill = \"blue\", color = \"black\") +\n  coord_flip() +\n  labs(title = \"versicolor\")+\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank() #this was by GPT\n  )\n\n\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\n# 4 Column Chart\n# getting means of Petal length and width for each species\n# and mean sepal length and sepal width\niris_means &lt;- iris %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    mean_sepal_length = mean(Sepal.Length),\n    mean_sepal_width = mean(Sepal.Width),\n    mean_petal_length = mean(Petal.Length),\n    mean_petal_width = mean(Petal.Width)\n  ) %&gt;%\n  pivot_longer(\n    cols = -Species,\n    names_to = \"Measurement\",\n    values_to = \"MeanValue\"\n    )\n\nggplot(iris_means, aes(x = Measurement, y = MeanValue, fill = Species)) +\n  geom_col(position = position_dodge(width = 0.8)) + \n  labs(title = \"Mean Iris Measurements by Species\",\n       x = \"Measurement\", y = \"Mean Value\") + \n  theme_minimal(base_size = 12) +\n  scale_fill_manual(values = c(\"steelblue\", \"orange\", \"seagreen\"))\n\n\n\n\n\n\n\n\n\nClass coding competition\n\n\nlibrary(ggplot2)\nmpg &lt;- as.data.frame(mpg)\n#2seater, compact, midsize, minivan, pickup, subcompact, suv scatterplots in one view\nggplot(mpg, aes(x=displ, y=hwy)) +\n  geom_point(color = \"black\") +\n  facet_wrap(~ class) +\n  labs(x=\"displ\",\n       y=\"hwy\") +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n#improving the chart\nggplot(mpg, aes(x=displ, y=hwy)) +\n  geom_point(color = \"blue\", size=2, alpha=0.3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#E65100\", linewidth = 0.8) +\n  facet_wrap(~ class) +\n  labs(title=\"Engine Displacement vs Highway MPG by Vehicle Class\",\n       x=\"Engine Displacement (liters)\",\n       y=\"Highway Miles per Gallon (MPG)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size=16, face=\"bold\"),\n    axis.title.x = element_text(size=12),\n    axis.title.y = element_text(size=12)\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n# GPT was used for picking colors and family.\n# GPT was used for adjusting the format of the code.\nlibrary(ggplot2)\nlibrary(scales)   # for alpha()\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\ndata(iris)\ncolor1 &lt;- \"#18A3A380\"\ncolor2 &lt;- \"#FF4D8DCC\"\ncolor3 &lt;- \"#7A7A7A\"\ncolor4 &lt;- \"#000000\"\nbase_family &lt;- \"sans\"\n\n# custom theme used across plots\ntheme1 &lt;- function() {\n  theme_minimal(base_family = base_family) +\n    theme(\n      text        = element_text(family = base_family, colour = color4),\n      plot.title  = element_text(face = \"bold\", colour = color4, size = 13),\n      axis.title  = element_text(colour = color4),\n      axis.text   = element_text(colour = color3),\n      panel.grid.major = element_line(color = scales::alpha(color3, 0.3), linetype = \"dotted\"),\n      panel.grid.minor = element_blank()\n    )\n}\n\n\nHisto &lt;- function(){\n  hist(iris$Sepal.Length,\n       main=\"Distribution of Sepal Length (iris)\",\n       col=color1, border=color3)\n}\n\nBar1 &lt;- function(){\n  barplot(table(iris$Species),\n          col=c(color1,color2,color3),\n          border=color4,\n          main=\"Count by Species\",\n          xlab=\"Species\", ylab=\"Count\")\n}\n\nBar2 &lt;- function(){\n  barplot(table(iris$Species),\n          horiz=TRUE,\n          col=c(color1,color2,color3),\n          border=color4,\n          main=\"Count by Species (Horizontal)\",\n          xlab=\"Count\", ylab=\"Species\")\n}\n\nPie &lt;- function(){\n  pie(table(iris$Species),\n      col=c(color1,color2,color3),\n      main=\"Species Composition\",\n      clockwise=TRUE)\n}\n\nBox &lt;- function(){\n  boxplot(Sepal.Length~Species, data=iris,\n          col=c(color1,color2,color3),\n          main=\"Sepal Length by Species\",\n          xlab=\"Species\", ylab=\"Sepal Length (cm)\")\n}\n\nScat &lt;- function(){\n  plot(iris$Petal.Length, iris$Sepal.Length,\n       main=\"Sepal vs Petal Length\",\n       xlab=\"Petal Length (cm)\", ylab=\"Sepal Length (cm)\",\n       pch=19, col=color1)\n}\n\n\nlibrary(gridExtra)\n\npar(mfrow=c(2,3), mar=c(4,4,2.5,1), family=\"sans\")\nHisto(); Bar1(); Bar2(); Pie(); Box(); Scat()\n\n\n\n\n\n\n\n\n\ndraw6 &lt;- function(){\n  par(mfrow=c(2,3), mar=c(4,4,2.5,1), family=base_family)\n  Histo(); Bar1(); Bar2(); Pie(); Box(); Scat()\n}\n\nsave_plot &lt;- function(fmt, file){\n  switch(fmt,\n    pdf  = pdf(file, width=10, height=7, family=base_family),\n    jpg  = jpeg(file, width=2400, height=1600, res=300, quality=95),\n    svg  = svg(file, width=2400, height=1600),\n    tiff = tiff(file, width=2400, height=1600, res=300),\n    bmp  = bmp(file, width=2400, height=1600, res=300), # cannot find bmg, and was told it might be .bmp by GPT\n  )\n  draw6(); invisible(dev.off())\n}\n\n\nsave_plot(\"pdf\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.pdf\")\nsave_plot(\"jpg\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.jpg\")\nsave_plot(\"svg\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.svg\")\nsave_plot(\"tiff\", \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.tiff\")\nsave_plot(\"bmp\",  \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io/baseR_6plots.bmp\")\n\nPDF of base R plots\nJPG of base R plots\nSVG of base R plots\nTIFF of base R plots\nBMP of base R plots\n\nggHisto &lt;- ggplot(iris, aes(x=Sepal.Length)) +\n  geom_histogram(fill=color1, color=color3, bins=20) +\n  labs(title=\"Distribution of Sepal Length (iris)\") +\n  theme1()\n\nggBar1 &lt;- ggplot(iris, aes(x=Species, fill=Species)) +\n  geom_bar(color=color4) +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Count by Species\") +\n  theme1() + ggplot2::theme(legend.position=\"none\")\n\nggBar2 &lt;- ggplot(iris, aes(x=Species, fill=Species)) +\n  geom_bar(color=color4) + coord_flip() +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Count by Species (Horizontal)\") +\n  theme1() + ggplot2::theme(legend.position=\"none\")\n\ndf &lt;- as.data.frame(prop.table(table(iris$Species)))\ncolnames(df) &lt;- c(\"Species\",\"prop\")\nggPie &lt;- ggplot(df, aes(x=\"\", y=prop, fill=Species)) +\n  geom_col(width=1, color=NA) + coord_polar(theta=\"y\") +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Species Composition\") +\n  theme1() + ggplot2::theme(axis.text=ggplot2::element_blank(),\n                            axis.title=ggplot2::element_blank(),\n                            panel.grid=ggplot2::element_blank(),\n                            legend.position=\"right\")\n\nggBox &lt;- ggplot(iris, aes(x=Species, y=Sepal.Length, fill=Species)) +\n  geom_boxplot(color=color4) +\n  scale_fill_manual(values=c(color1,color2,color3)) +\n  labs(title=\"Sepal Length by Species\") +\n  theme1() + ggplot2::theme(legend.position=\"none\")\n\nggScat &lt;- ggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point(color=color1, size=2) +\n  labs(title=\"Sepal vs Petal Length\") +\n  theme1()\n\n\ngridExtra::grid.arrange(ggHisto, ggBar1, ggBar2, ggPie, ggBox, ggScat, ncol = 3)\n\n\n\n\n\n\n\n\n\ncombo &lt;- gridExtra::arrangeGrob(ggHisto, ggBar1, ggBar2, ggPie, ggBox, ggScat, ncol = 3)\noutdir &lt;- \"/Users/buttegg/Documents/IAmTryingToUseQuartoDoSthCool/buttegggggggg.github.io\"\nformats &lt;- c(\"pdf\", \"jpg\", \"svg\", \"tiff\", \"bmp\")\n\nfor (fmt in formats) {\n  outpath &lt;- file.path(outdir, paste0(\"ggplot_6plots.\", fmt))\n  ggplot2::ggsave(\n    filename = outpath,\n    plot = combo,\n    width = 10, height = 7, dpi = 300\n  )\n}\n\nPDF of ggplot2 plots\nJPG of ggplot2 plots\nSVG of ggplot2 plots\nTIFF of ggplot2 plots\nBMP of ggplot2 plots"
  },
  {
    "objectID": "EPPS6356.html#reviews",
    "href": "EPPS6356.html#reviews",
    "title": "Data Visualization",
    "section": "Reviews",
    "text": "Reviews\n\nReview: Inge Druckrey – Teaching to See\nReview: Journalism in the Age of Data\nReview: The Future of Data Analysis\nReview: Data Visualization and Data Science\nReview: The Week in Charts & 2024 The Year in Charts"
  },
  {
    "objectID": "EPPS6356.html#notes",
    "href": "EPPS6356.html#notes",
    "title": "Data Visualization",
    "section": "Notes",
    "text": "Notes\n\nNotes: Big Data Pitfalls"
  },
  {
    "objectID": "EPPS6356.html#checklist",
    "href": "EPPS6356.html#checklist",
    "title": "Data Visualization",
    "section": "Checklist",
    "text": "Checklist\n\nTzu-Yuan’s Data Guide Checklist"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "This is Tzu-Yuan’s Quarto website"
  },
  {
    "objectID": "about.html#about-this-site",
    "href": "about.html#about-this-site",
    "title": "About",
    "section": "",
    "text": "This site is a working portfolio and notebook.\nIt documents selected projects, visual studies, and experiments as they evolve.\nNot all content represents final results. Some materials are exploratory or incomplete."
  },
  {
    "objectID": "EPPS6354.html",
    "href": "EPPS6354.html",
    "title": "Information Management",
    "section": "",
    "text": "Name and describe three applications you have used that employed a database system to store and access persistent data. (e.g. airlines, online trade, banking, university system)\nFor the first question, one example that comes to mind is video games. In video games, a player’s level and experience points, as well as the items and equipment they have obtained, are recorded, so the player can still access them the next time they log in. Another example is online shopping. For instance, Amazon records information such as the price of each product, the catalog it belongs to, whether it is eligible for free shipping, and whether it is in stock. A third example is a streaming platform, such as Netflix, which records a user’s region and subscription level. All of this data is stored persistently and can be accessed at a later time.\n\n\n\nPropose three applications in domain projects (e.g. criminology, economics, brain science, etc.) Be sure you include: i. Purpose ii. Functions iii. Simple interface design\n\n\n\n\nThe main purpose of this wardrobe management database is to minimize the time spent choosing outfits before going out.\nFor many people, the difficulty in daily outfit selection is not a lack of clothing, but the need to simultaneously consider colors, styles, occasions, and overall coordination, which leads to a high decision-making cost.\nTherefore, I model the wardrobe as a relational database, which not only records individual clothing items but also describes the relationships between items, allowing outfit selection to be handled in a systematic way.\nBy structuring clothing data, this system aims to transform “rethinking what to wear every day” into “quickly selecting optimal combinations from a database.”\n\n\n\nIn this system, each clothing item is treated as a data entity and described using a set of attributes, such as:\n\ncategory (T-shirts, jeans, outerwear, shoes),\ncolor (including the proportion of each color),\nstyle (clean-fit, formal, vintage, sports, etc.),\nmaterial (denim, linen, cotton).\n\nThese attributes are normalized into multiple tables, and many-to-many relationships are used to represent that a single item can belong to multiple styles or be suitable for different occasions.\nThe core function of this database is not only to store items, but to describe the compatibility between items.\nThe system uses compatibility rules to define:\n\nVisual aesthetic constraints, such as avoiding more than three colors in a single outfit and limiting the number of style tags to maintain overall consistency\nClimate adaptability, where combinations are evaluated based on insulation-related variables to ensure balanced warmth between upper and lower body layers, and higher overall insulation is preferred as the temperature decreases\n\nWhen a user selects a specific item (for example, a pink T-shirt), the system can immediately recommend other highly compatible items (such as light blue jeans and white sneakers) based on database relationships and rules, and rank these combinations by compatibility score to help the user make decisions more efficiently.\nIn addition, as data accumulates, the system can analyze the overall structure of the wardrobe, such as:\n\nWhether certain styles or clothing categories are lacking\nWhether colors or item types are overly concentrated\nWhether newly purchased items overlap in function with existing ones\nWhich older items have not been used for a long time and could be considered for removal\n\nThis allows the wardrobe to function not just as an item list, but as a system that can be queried, analyzed, and optimized, and that can be extended to daily life applications such as outfit recommendations and purchase decision support.\nThis problem is particularly well suited for a relational database, because outfit selection inherently involves structured data and many-to-many relationships (such as items, styles, and compatibility rules), which can be efficiently combined and analyzed through relational queries.\n\n\n\nWhen users enter the system, the home page displays a table view of all items in the wardrobe, including basic information such as category, color, style, material, and seasonality. The interface supports multi-select functionality.\nUsers can select one or more items they plan to wear and submit their selection to generate outfit results.\nBased on the selected items and the compatibility rules stored in the database, the system generates multiple outfit candidates.\nThe outfit results page provides different sorting options, such as sorting by comfort score, aesthetic score, or climate fit score.\nEach outfit displays its corresponding numerical scores, allowing users to quickly compare options and select the most suitable combination without repeatedly trying on clothes or overthinking the decision.\nThe interface supports fast decision-making: select items → generate outfits → sort by scores → pick the best match.\n\n\n\n\n\n\nThe purpose of this 3D printing farm database is to systematize the entire workflow—from customer order intake to automated estimation, machine scheduling, and progress tracking—so the farm can operate efficiently as order volume grows. The goals are to shorten turnaround time, reduce human scheduling errors, improve machine utilization, and maximize profitability.\nIn practice, 3D printing orders vary widely (model size, material, resolution, multi-color requirements, and post-processing such as painting). If pricing and scheduling rely on manual judgment, it is easy to underestimate time/cost, assign the wrong machine, or create bottlenecks in the order queue. Therefore, this system uses a relational database to store orders, machine capabilities, material usage, and scheduling states in a structured way, enabling fast and consistent decisions through rules and queries.\n\n\n\nOrder intake & requirement tagging (Order Intake & Requirement Tagging)\nWhen a customer submits an order, the system stores it as an order record with structured attributes, such as:\n\nModel size and volume (bounding box / volume)\nPrinting type (FDM / SLA)\nResolution settings (layer height / resolution)\nMulti-color requirement (multi-color)\nMaterial type (material type)\nPost-processing needs (post-processing, e.g., painting/sanding)\nOther customization requests (stored as tags)\n\nThese fields can be normalized into multiple tables, with many-to-many relationships used to represent that a single order can have multiple requirement tags.\nPer-machine estimation (Per-Machine Estimation)\nThe key is not only to calculate an overall price for the order, but to estimate how the same order would perform on different machines, since time, cost, and completion time may vary by machine. This supports better machine assignment and scheduling decisions.\nFor each candidate machine, the system applies pricing rules or an estimation model to perform per-machine estimation, including:\n\nEstimated print time (estimated print time)\nEstimated material usage (estimated material usage)\nMachine-specific estimated cost & quote (machine-specific estimated cost & quote)\nEstimated completion time (estimated completion time, considering current workload)\n\nThe system stores these “order × machine” estimates for querying and ranking using different objective functions, such as lowest cost, earliest completion, or the most stable option within a deadline.\nOrder queue & status tracking (Order Queue & Status Tracking)\nAll orders are automatically added to an order queue (order list), and each order maintains a clear status, such as:\n\npending\nqueued\nprinting\npost-processing\ncompleted\nfailed\n\nManagers can query:\n\nWhat is currently in the queue and its priority\nWhich orders are printing vs. waiting for machines\nWhich failed orders require reprinting or manual intervention\n\nMachine capability modeling & assignment recommendations (Machine Capability & Assignment)\nThe database stores each machine’s capabilities and constraints, such as: - Machine type: multi-color / single-color / SLA / FDM - Maximum build volume (max build volume) - Supported materials (supported materials) - Speed/quality profile (speed/quality profile) - Current workload and availability (workload & availability)\nWhen a new order arrives, the system first performs constraint filtering (e.g., size, material, multi-color requirements) to identify feasible machines, then uses per-machine estimation to generate recommended assignments, for example:\n\nEarliest completion time (earliest completion time)\nLowest estimated cost (lowest estimated cost)\nBalanced option (deadline + stability)\n\nThis turns scheduling into a decision-support process rather than manual guesswork.\n\n\n\nOn the customer side, the system provides a customer order page where users can upload a 3D model or specify printing requirements such as size, material, resolution, multi-color options, and post-processing needs. Based on this information, the system automatically returns an estimated price and an estimated delivery time.\nOn the admin side, the system offers an order dashboard that displays the current order queue and order statuses. Administrators can sort or filter orders by deadline, priority, or processing status to manage workflow more efficiently.\nThe system also includes a machine dashboard that lists all available machines along with their machine type, maximum build volume, supported materials, current workload, and estimated availability. This allows operators to quickly understand machine capacity and constraints.\nWhen an order is selected, the scheduling view presents a list of candidate machines that can fulfill the order. For each candidate machine, the system displays the estimated print time, estimated material usage, machine-specific cost and quote, and estimated completion time. The interface supports one-click sorting options, such as fastest, cheapest, or most stable, to assist administrators in making assignment decisions.\nThe interface supports efficient operations: submit order → per-machine estimation → queue order → recommend machines → schedule & track progress.\n\n\n\n\n\n\nThe purpose of this system is to manage the core information of a farm—such as fields, crop types, growth stages, and irrigation equipment—using a relational database.\nAt the same time, the system retrieves and stores weather data through APIs provided by weather forecast services, and combines this information with a set of irrigation rules to automatically generate a daily irrigation schedule.\nThe goal is to reduce manual decision-making costs while improving water-use efficiency and consistency in crop management.\n\n\n\nIn this system, the database is not used only for data storage. Its core function is to integrate internal farm information with external weather data and automatically generate irrigation decisions based on predefined rules.\nCore Data Management\nThe system uses a relational schema to manage the main entities of the farm, including:\n\nField: field ID, location, area, and the crop currently planted\nCrop: crop type and its basic water requirements\nGrowth Stage: stages such as germination, growth, flowering, and fruiting, each with different water needs\nIrrigation Equipment: equipment type (e.g., drip irrigation, sprinkler), flow rate or efficiency factor, and availability status\n\nThese entities are connected through relationships. For example, each field is associated with a specific crop and a current growth stage, and can be assigned available irrigation equipment.\nWeather Data Integration\nThe system retrieves weather information through external weather forecast APIs, such as:\n\nPredicted rainfall amount\nProbability of precipitation\nTemperature range\n\nThis weather data is stored in the database and used as an important input for daily irrigation decisions, without requiring manual input from users.\nIrrigation Rules and Schedule Generation\nThe system maintains a set of irrigation rules that describe irrigation requirements under different conditions, such as:\n\nCrop type × growth stage → recommended baseline irrigation amount\nIf predicted rainfall exceeds a certain threshold → automatically reduce or cancel irrigation for the day\nDifferences in irrigation equipment efficiency → adjust actual irrigation duration\n\nWhen the daily scheduling process runs, the system combines:\n\nThe crop type and growth stage of each field\nThe weather forecast for the day\nThe availability and efficiency of irrigation equipment\n\nBased on this information, the system automatically generates a daily irrigation schedule, indicating whether each field requires irrigation and the recommended water amount or irrigation time.\n\n\n\nWhen users enter the system, the home page displays a table view of all fields on the farm, including the current crop type, growth stage, and the system’s irrigation recommendation for the day.\nUsers can generate the daily irrigation schedule with a single action. Based on field information, weather forecasts, and irrigation rules, the system lists which fields require irrigation and provides recommended water amounts or irrigation durations.\nThe schedule is presented in a simple list format, allowing users to quickly review and execute irrigation tasks. After completion, users can mark irrigation status for record-keeping and future reference.\n\n\n\n\n\nWhat are the things current database system cannot do?\nCurrent database systems are not capable of understanding the semantics behind data. As a result, in more complex applications, they often rely on manually defined rules or continuously adjusted weights to produce reasonable outputs. In addition, databases are limited in handling cross-context decision-making, where multiple competing objectives must be balanced simultaneously.\nFor example, in a wardrobe management database, the system can evaluate outfits based on structured criteria such as color combinations, style tags, material properties, and weather conditions. It can assign scores for factors like aesthetic quality, comfort, and climate suitability, and generate multiple candidate outfits that satisfy predefined rules. However, the database cannot determine which outfit represents the optimal balance among being visually appealing, comfortable, and suitable for the weather.\nThis limitation arises because preferences such as “looking good” or “feeling comfortable” are inherently subjective and context-dependent, and there is no single optimal solution that applies to all users or situations. Therefore, the role of the database is not to make the final decision, but to support decision-making by filtering infeasible options, structuring relevant information, and presenting comparable alternatives with transparent evaluation metrics.\nUltimately, the final choice must be made by the user, who can decide whether to prioritize comfort, aesthetics, or climate suitability in a given context. This highlights a fundamental limitation of current database systems: they are effective at decision support, but they cannot replace human judgment in complex, value-driven decisions.\n\n\n\nDescribe at least three tables that might be used to store information in a social-network/social media system such as Twitter or Reddit.\nA social-network or social media system such as Twitter or Reddit may be supported by at least the following three core tables:\n1. User Table\nThe user table stores basic information about users, such as: - user_id - username - account creation time - profile metadata (e.g., bio or status)\nThis table represents the identities of users and serves as a reference for other tables in the system.\n2. Post Table\nThe post table stores content created by users, such as:\n\npost_id\nauthor_id (foreign key referencing the User table)\ncontent\ntimestamp\n\nEach post is associated with a specific user, forming a one-to-many relationship between users and posts.\n3. Comment Table\nThe comment table stores replies to posts (or other comments), such as:\n\ncomment_id\npost_id (foreign key referencing the Post table)\nauthor_id\ncontent\ntimestamp\n\nThis table supports threaded discussions and allows multiple users to participate in conversations under the same post.\nThese tables are separated to support relational queries, maintain data consistency, and enable efficient retrieval of users, posts, and discussion threads.\n\n\n\n\n\n\nWhat are the differences between relation schema, relation, and instance? Give an example using the university database to illustrate.\n\nRelation Schema = The logical structure of a relation: a list of attribute names and their domains. It does not change over time.\nExample: instructor(ID, name, dept_name, salary)\nRelation = Informally used to refer to both the schema and instance together.\nExample: “The department relation” can refer to either the schema department(dept_name, building, budget) or the actual data it currently holds.\nInstance = A snapshot of the actual data in a relation at a given point in time. It changes as tuples are inserted, updated, or deleted.\nExample: The department relation instance in Figure 2.5 contains 7 tuples. If the university adds a “Data Science” department, the instance grows to 8 tuples, but the schema remains department(dept_name, building, budget).\n\n\n\n\nDraw a schema diagram for the following bank database. Identify primary keys (underlined) and foreign keys.\nThe bank database consists of the following relations:\n\nbranch(branch_name, branch_city, assets)\ncustomer(ID, customer_name, customer_street, customer_city)\nloan(loan_number, branch_name, amount)\nborrower(ID, loan_number)\naccount(account_number, branch_name, balance)\ndepositor(ID, account_number)\n\n\n\n\nBank Database Schema Diagram\n\n\n\n\n\nDescribe two ways artificial intelligence or LLM can assist in managing or querying a database. In your answer, briefly explain how each method improves efficiency or accuracy compared to traditional (non-AI) approaches. (3–5 sentences)\n\nNatural Language to SQL (Querying): LLMs can translate plain language questions directly into executable SQL queries, lowering the barrier for non-technical users and reducing syntax errors compared to writing SQL manually.\nAI-Driven Database Tuning (Managing): LLMs can automatically analyze slow queries and recommend index optimizations, replacing the traditionally time-consuming process of a DBA manually examining query logs and execution plans.\n\nOverall, both approaches reduce the need for specialized expertise and allow faster, more accurate database operations compared to traditional manual methods.\n\n\n\n\n\n\nOpen the Online SQL interpreter and load the university database.\n\n\n\nWrite SQL codes to get a list of: i. Student IDs, ii. Instructors, iii. Departments\n\n\n\nQ2 — Student IDs (from takes), Instructors, and Departments\n\n\n\n\n\nWrite SQL codes to do the following queries:\ni. Find the ID and name of each student who has taken at least one Comp. Sci. course; make sure there are no duplicate names in the result.\n\n\n\nQ3i — Students who took at least one Comp. Sci. course\n\n\nii. Add grades to the list\n\n\n\nQ3ii — Add grades to the result\n\n\niii. Find the ID and name of each student who has not taken any course offered before 2017.\n\n\n\nQ3iii — Students who have not taken any course before 2017\n\n\niv. For each department, find the maximum salary of instructors in that department.\n\n\n\nQ3iv — Maximum instructor salary per department\n\n\nv. Find the lowest, across all departments, of the per-department maximum salary computed by the preceding query.\n\n\n\nQ3v — Lowest of the per-department maximum salaries\n\n\nvi. Add names to the list\n\n\n\nQ3vi — Add instructor names to the result\n\n\n\n\n\nFind instructor (with name and ID) who has never given an A grade in any course she or he has taught. (Instructors who have never taught a course trivially satisfy this condition.)\n\n\n\nQ4 — Instructors who have never given an A grade"
  },
  {
    "objectID": "EPPS6354.html#assignments",
    "href": "EPPS6354.html#assignments",
    "title": "Information Management",
    "section": "",
    "text": "Name and describe three applications you have used that employed a database system to store and access persistent data. (e.g. airlines, online trade, banking, university system)\nFor the first question, one example that comes to mind is video games. In video games, a player’s level and experience points, as well as the items and equipment they have obtained, are recorded, so the player can still access them the next time they log in. Another example is online shopping. For instance, Amazon records information such as the price of each product, the catalog it belongs to, whether it is eligible for free shipping, and whether it is in stock. A third example is a streaming platform, such as Netflix, which records a user’s region and subscription level. All of this data is stored persistently and can be accessed at a later time.\n\n\n\nPropose three applications in domain projects (e.g. criminology, economics, brain science, etc.) Be sure you include: i. Purpose ii. Functions iii. Simple interface design\n\n\n\n\nThe main purpose of this wardrobe management database is to minimize the time spent choosing outfits before going out.\nFor many people, the difficulty in daily outfit selection is not a lack of clothing, but the need to simultaneously consider colors, styles, occasions, and overall coordination, which leads to a high decision-making cost.\nTherefore, I model the wardrobe as a relational database, which not only records individual clothing items but also describes the relationships between items, allowing outfit selection to be handled in a systematic way.\nBy structuring clothing data, this system aims to transform “rethinking what to wear every day” into “quickly selecting optimal combinations from a database.”\n\n\n\nIn this system, each clothing item is treated as a data entity and described using a set of attributes, such as:\n\ncategory (T-shirts, jeans, outerwear, shoes),\ncolor (including the proportion of each color),\nstyle (clean-fit, formal, vintage, sports, etc.),\nmaterial (denim, linen, cotton).\n\nThese attributes are normalized into multiple tables, and many-to-many relationships are used to represent that a single item can belong to multiple styles or be suitable for different occasions.\nThe core function of this database is not only to store items, but to describe the compatibility between items.\nThe system uses compatibility rules to define:\n\nVisual aesthetic constraints, such as avoiding more than three colors in a single outfit and limiting the number of style tags to maintain overall consistency\nClimate adaptability, where combinations are evaluated based on insulation-related variables to ensure balanced warmth between upper and lower body layers, and higher overall insulation is preferred as the temperature decreases\n\nWhen a user selects a specific item (for example, a pink T-shirt), the system can immediately recommend other highly compatible items (such as light blue jeans and white sneakers) based on database relationships and rules, and rank these combinations by compatibility score to help the user make decisions more efficiently.\nIn addition, as data accumulates, the system can analyze the overall structure of the wardrobe, such as:\n\nWhether certain styles or clothing categories are lacking\nWhether colors or item types are overly concentrated\nWhether newly purchased items overlap in function with existing ones\nWhich older items have not been used for a long time and could be considered for removal\n\nThis allows the wardrobe to function not just as an item list, but as a system that can be queried, analyzed, and optimized, and that can be extended to daily life applications such as outfit recommendations and purchase decision support.\nThis problem is particularly well suited for a relational database, because outfit selection inherently involves structured data and many-to-many relationships (such as items, styles, and compatibility rules), which can be efficiently combined and analyzed through relational queries.\n\n\n\nWhen users enter the system, the home page displays a table view of all items in the wardrobe, including basic information such as category, color, style, material, and seasonality. The interface supports multi-select functionality.\nUsers can select one or more items they plan to wear and submit their selection to generate outfit results.\nBased on the selected items and the compatibility rules stored in the database, the system generates multiple outfit candidates.\nThe outfit results page provides different sorting options, such as sorting by comfort score, aesthetic score, or climate fit score.\nEach outfit displays its corresponding numerical scores, allowing users to quickly compare options and select the most suitable combination without repeatedly trying on clothes or overthinking the decision.\nThe interface supports fast decision-making: select items → generate outfits → sort by scores → pick the best match.\n\n\n\n\n\n\nThe purpose of this 3D printing farm database is to systematize the entire workflow—from customer order intake to automated estimation, machine scheduling, and progress tracking—so the farm can operate efficiently as order volume grows. The goals are to shorten turnaround time, reduce human scheduling errors, improve machine utilization, and maximize profitability.\nIn practice, 3D printing orders vary widely (model size, material, resolution, multi-color requirements, and post-processing such as painting). If pricing and scheduling rely on manual judgment, it is easy to underestimate time/cost, assign the wrong machine, or create bottlenecks in the order queue. Therefore, this system uses a relational database to store orders, machine capabilities, material usage, and scheduling states in a structured way, enabling fast and consistent decisions through rules and queries.\n\n\n\nOrder intake & requirement tagging (Order Intake & Requirement Tagging)\nWhen a customer submits an order, the system stores it as an order record with structured attributes, such as:\n\nModel size and volume (bounding box / volume)\nPrinting type (FDM / SLA)\nResolution settings (layer height / resolution)\nMulti-color requirement (multi-color)\nMaterial type (material type)\nPost-processing needs (post-processing, e.g., painting/sanding)\nOther customization requests (stored as tags)\n\nThese fields can be normalized into multiple tables, with many-to-many relationships used to represent that a single order can have multiple requirement tags.\nPer-machine estimation (Per-Machine Estimation)\nThe key is not only to calculate an overall price for the order, but to estimate how the same order would perform on different machines, since time, cost, and completion time may vary by machine. This supports better machine assignment and scheduling decisions.\nFor each candidate machine, the system applies pricing rules or an estimation model to perform per-machine estimation, including:\n\nEstimated print time (estimated print time)\nEstimated material usage (estimated material usage)\nMachine-specific estimated cost & quote (machine-specific estimated cost & quote)\nEstimated completion time (estimated completion time, considering current workload)\n\nThe system stores these “order × machine” estimates for querying and ranking using different objective functions, such as lowest cost, earliest completion, or the most stable option within a deadline.\nOrder queue & status tracking (Order Queue & Status Tracking)\nAll orders are automatically added to an order queue (order list), and each order maintains a clear status, such as:\n\npending\nqueued\nprinting\npost-processing\ncompleted\nfailed\n\nManagers can query:\n\nWhat is currently in the queue and its priority\nWhich orders are printing vs. waiting for machines\nWhich failed orders require reprinting or manual intervention\n\nMachine capability modeling & assignment recommendations (Machine Capability & Assignment)\nThe database stores each machine’s capabilities and constraints, such as: - Machine type: multi-color / single-color / SLA / FDM - Maximum build volume (max build volume) - Supported materials (supported materials) - Speed/quality profile (speed/quality profile) - Current workload and availability (workload & availability)\nWhen a new order arrives, the system first performs constraint filtering (e.g., size, material, multi-color requirements) to identify feasible machines, then uses per-machine estimation to generate recommended assignments, for example:\n\nEarliest completion time (earliest completion time)\nLowest estimated cost (lowest estimated cost)\nBalanced option (deadline + stability)\n\nThis turns scheduling into a decision-support process rather than manual guesswork.\n\n\n\nOn the customer side, the system provides a customer order page where users can upload a 3D model or specify printing requirements such as size, material, resolution, multi-color options, and post-processing needs. Based on this information, the system automatically returns an estimated price and an estimated delivery time.\nOn the admin side, the system offers an order dashboard that displays the current order queue and order statuses. Administrators can sort or filter orders by deadline, priority, or processing status to manage workflow more efficiently.\nThe system also includes a machine dashboard that lists all available machines along with their machine type, maximum build volume, supported materials, current workload, and estimated availability. This allows operators to quickly understand machine capacity and constraints.\nWhen an order is selected, the scheduling view presents a list of candidate machines that can fulfill the order. For each candidate machine, the system displays the estimated print time, estimated material usage, machine-specific cost and quote, and estimated completion time. The interface supports one-click sorting options, such as fastest, cheapest, or most stable, to assist administrators in making assignment decisions.\nThe interface supports efficient operations: submit order → per-machine estimation → queue order → recommend machines → schedule & track progress.\n\n\n\n\n\n\nThe purpose of this system is to manage the core information of a farm—such as fields, crop types, growth stages, and irrigation equipment—using a relational database.\nAt the same time, the system retrieves and stores weather data through APIs provided by weather forecast services, and combines this information with a set of irrigation rules to automatically generate a daily irrigation schedule.\nThe goal is to reduce manual decision-making costs while improving water-use efficiency and consistency in crop management.\n\n\n\nIn this system, the database is not used only for data storage. Its core function is to integrate internal farm information with external weather data and automatically generate irrigation decisions based on predefined rules.\nCore Data Management\nThe system uses a relational schema to manage the main entities of the farm, including:\n\nField: field ID, location, area, and the crop currently planted\nCrop: crop type and its basic water requirements\nGrowth Stage: stages such as germination, growth, flowering, and fruiting, each with different water needs\nIrrigation Equipment: equipment type (e.g., drip irrigation, sprinkler), flow rate or efficiency factor, and availability status\n\nThese entities are connected through relationships. For example, each field is associated with a specific crop and a current growth stage, and can be assigned available irrigation equipment.\nWeather Data Integration\nThe system retrieves weather information through external weather forecast APIs, such as:\n\nPredicted rainfall amount\nProbability of precipitation\nTemperature range\n\nThis weather data is stored in the database and used as an important input for daily irrigation decisions, without requiring manual input from users.\nIrrigation Rules and Schedule Generation\nThe system maintains a set of irrigation rules that describe irrigation requirements under different conditions, such as:\n\nCrop type × growth stage → recommended baseline irrigation amount\nIf predicted rainfall exceeds a certain threshold → automatically reduce or cancel irrigation for the day\nDifferences in irrigation equipment efficiency → adjust actual irrigation duration\n\nWhen the daily scheduling process runs, the system combines:\n\nThe crop type and growth stage of each field\nThe weather forecast for the day\nThe availability and efficiency of irrigation equipment\n\nBased on this information, the system automatically generates a daily irrigation schedule, indicating whether each field requires irrigation and the recommended water amount or irrigation time.\n\n\n\nWhen users enter the system, the home page displays a table view of all fields on the farm, including the current crop type, growth stage, and the system’s irrigation recommendation for the day.\nUsers can generate the daily irrigation schedule with a single action. Based on field information, weather forecasts, and irrigation rules, the system lists which fields require irrigation and provides recommended water amounts or irrigation durations.\nThe schedule is presented in a simple list format, allowing users to quickly review and execute irrigation tasks. After completion, users can mark irrigation status for record-keeping and future reference.\n\n\n\n\n\nWhat are the things current database system cannot do?\nCurrent database systems are not capable of understanding the semantics behind data. As a result, in more complex applications, they often rely on manually defined rules or continuously adjusted weights to produce reasonable outputs. In addition, databases are limited in handling cross-context decision-making, where multiple competing objectives must be balanced simultaneously.\nFor example, in a wardrobe management database, the system can evaluate outfits based on structured criteria such as color combinations, style tags, material properties, and weather conditions. It can assign scores for factors like aesthetic quality, comfort, and climate suitability, and generate multiple candidate outfits that satisfy predefined rules. However, the database cannot determine which outfit represents the optimal balance among being visually appealing, comfortable, and suitable for the weather.\nThis limitation arises because preferences such as “looking good” or “feeling comfortable” are inherently subjective and context-dependent, and there is no single optimal solution that applies to all users or situations. Therefore, the role of the database is not to make the final decision, but to support decision-making by filtering infeasible options, structuring relevant information, and presenting comparable alternatives with transparent evaluation metrics.\nUltimately, the final choice must be made by the user, who can decide whether to prioritize comfort, aesthetics, or climate suitability in a given context. This highlights a fundamental limitation of current database systems: they are effective at decision support, but they cannot replace human judgment in complex, value-driven decisions.\n\n\n\nDescribe at least three tables that might be used to store information in a social-network/social media system such as Twitter or Reddit.\nA social-network or social media system such as Twitter or Reddit may be supported by at least the following three core tables:\n1. User Table\nThe user table stores basic information about users, such as: - user_id - username - account creation time - profile metadata (e.g., bio or status)\nThis table represents the identities of users and serves as a reference for other tables in the system.\n2. Post Table\nThe post table stores content created by users, such as:\n\npost_id\nauthor_id (foreign key referencing the User table)\ncontent\ntimestamp\n\nEach post is associated with a specific user, forming a one-to-many relationship between users and posts.\n3. Comment Table\nThe comment table stores replies to posts (or other comments), such as:\n\ncomment_id\npost_id (foreign key referencing the Post table)\nauthor_id\ncontent\ntimestamp\n\nThis table supports threaded discussions and allows multiple users to participate in conversations under the same post.\nThese tables are separated to support relational queries, maintain data consistency, and enable efficient retrieval of users, posts, and discussion threads.\n\n\n\n\n\n\nWhat are the differences between relation schema, relation, and instance? Give an example using the university database to illustrate.\n\nRelation Schema = The logical structure of a relation: a list of attribute names and their domains. It does not change over time.\nExample: instructor(ID, name, dept_name, salary)\nRelation = Informally used to refer to both the schema and instance together.\nExample: “The department relation” can refer to either the schema department(dept_name, building, budget) or the actual data it currently holds.\nInstance = A snapshot of the actual data in a relation at a given point in time. It changes as tuples are inserted, updated, or deleted.\nExample: The department relation instance in Figure 2.5 contains 7 tuples. If the university adds a “Data Science” department, the instance grows to 8 tuples, but the schema remains department(dept_name, building, budget).\n\n\n\n\nDraw a schema diagram for the following bank database. Identify primary keys (underlined) and foreign keys.\nThe bank database consists of the following relations:\n\nbranch(branch_name, branch_city, assets)\ncustomer(ID, customer_name, customer_street, customer_city)\nloan(loan_number, branch_name, amount)\nborrower(ID, loan_number)\naccount(account_number, branch_name, balance)\ndepositor(ID, account_number)\n\n\n\n\nBank Database Schema Diagram\n\n\n\n\n\nDescribe two ways artificial intelligence or LLM can assist in managing or querying a database. In your answer, briefly explain how each method improves efficiency or accuracy compared to traditional (non-AI) approaches. (3–5 sentences)\n\nNatural Language to SQL (Querying): LLMs can translate plain language questions directly into executable SQL queries, lowering the barrier for non-technical users and reducing syntax errors compared to writing SQL manually.\nAI-Driven Database Tuning (Managing): LLMs can automatically analyze slow queries and recommend index optimizations, replacing the traditionally time-consuming process of a DBA manually examining query logs and execution plans.\n\nOverall, both approaches reduce the need for specialized expertise and allow faster, more accurate database operations compared to traditional manual methods.\n\n\n\n\n\n\nOpen the Online SQL interpreter and load the university database.\n\n\n\nWrite SQL codes to get a list of: i. Student IDs, ii. Instructors, iii. Departments\n\n\n\nQ2 — Student IDs (from takes), Instructors, and Departments\n\n\n\n\n\nWrite SQL codes to do the following queries:\ni. Find the ID and name of each student who has taken at least one Comp. Sci. course; make sure there are no duplicate names in the result.\n\n\n\nQ3i — Students who took at least one Comp. Sci. course\n\n\nii. Add grades to the list\n\n\n\nQ3ii — Add grades to the result\n\n\niii. Find the ID and name of each student who has not taken any course offered before 2017.\n\n\n\nQ3iii — Students who have not taken any course before 2017\n\n\niv. For each department, find the maximum salary of instructors in that department.\n\n\n\nQ3iv — Maximum instructor salary per department\n\n\nv. Find the lowest, across all departments, of the per-department maximum salary computed by the preceding query.\n\n\n\nQ3v — Lowest of the per-department maximum salaries\n\n\nvi. Add names to the list\n\n\n\nQ3vi — Add instructor names to the result\n\n\n\n\n\nFind instructor (with name and ID) who has never given an A grade in any course she or he has taught. (Instructors who have never taught a course trivially satisfy this condition.)\n\n\n\nQ4 — Instructors who have never given an A grade"
  },
  {
    "objectID": "EPPS6354_project.html",
    "href": "EPPS6354_project.html",
    "title": "Wardrobe Database — Final Project",
    "section": "",
    "text": "This project builds a single-user wardrobe management database whose primary goal is outfit recommendation. Each morning, the system reads the user’s calendar (to determine the occasion) and the current weather, filters out unwearable items (dirty or archived), and ranks candidate outfits using a rule-based scoring engine grounded in color theory, fabric compatibility, and style coherence. The output is the best recommended outfit plus 3–5 ranked alternatives, each with a score and a brief explanation.\nCore workflow:\nWake up → Read calendar (occasion) + weather → Filter wearable items → Score outfit combinations → Output recommendation\nThree scoring dimensions:\n\nColor — 60/30/10 color theory; each item carries a primary / secondary / accent color role, and the engine checks whether the combined outfit achieves a balanced palette.\nFabric — same-fabric bonus (suit effect), mixed-fabric reasonableness, and warmth adequacy relative to the weather.\nStyle — style-tag consistency across items, and style–occasion fit scores stored in StyleOccasionFit.\n\n\n\n\n\n\n\n\n\n\nerDiagram\n    User {\n        int user_id PK\n        string name\n    }\n    Category {\n        int category_id PK\n        string name\n    }\n    Color {\n        int color_id PK\n        string name\n    }\n    Fabric {\n        int fabric_id PK\n        string name\n        int warmth_weight\n        int breathability\n    }\n    StyleTag {\n        int style_id PK\n        string name\n    }\n    Occasion {\n        int occasion_id PK\n        string name\n        int target_formality_min\n        int target_formality_max\n    }\n    StyleOccasionFit {\n        int style_id FK\n        int occasion_id FK\n        int fit_score\n    }\n    CalendarEvent {\n        int event_id PK\n        int user_id FK\n        string event_name\n        int occasion_id FK\n        date event_date\n        time start_time\n    }\n    ClothingItem {\n        int item_id PK\n        int user_id FK\n        int category_id FK\n        int fabric_id FK\n        string brand\n        string item_name\n        int formality_score\n        int warmth_score\n        int clean_score\n        string status\n        datetime created_at\n    }\n    ItemStyle {\n        int item_id FK\n        int style_id FK\n    }\n    ItemColor {\n        int item_id FK\n        int color_id FK\n        string role\n    }\n    WeatherSnapshot {\n        int weather_id PK\n        string location\n        datetime captured_at\n        float temp_c\n        float feels_like_c\n        int humidity\n        float wind_speed\n        float precip_mm\n    }\n    WeatherCondition {\n        int condition_id PK\n        string name\n        float min_temp_c\n        float max_temp_c\n        float min_precip_mm\n        float max_precip_mm\n        float min_wind\n        float max_wind\n        float min_humidity\n        float max_humidity\n    }\n    Outfit {\n        int outfit_id PK\n        int user_id FK\n        int occasion_id FK\n        int weather_id FK\n        float total_score\n        string explanation\n        datetime created_at\n    }\n    OutfitItem {\n        int outfit_id FK\n        int item_id FK\n        string slot\n        int layer_order\n    }\n    OutfitScoringRule {\n        int score_rule_id PK\n        string name\n        string rule_type\n        int score_delta\n        string explanation_template\n        json condition_json\n        date valid_from\n        date valid_until\n    }\n    WearDegradeRule {\n        int degrade_rule_id PK\n        int category_id FK\n        int occasion_id FK\n        int condition_id FK\n        int delta_clean_score\n    }\n    WearEvent {\n        int event_id PK\n        int user_id FK\n        int outfit_id FK\n        int occasion_id FK\n        int weather_id FK\n        datetime worn_at\n    }\n    WearEventItem {\n        int event_id FK\n        int item_id FK\n        int delta_applied\n        int clean_score_after\n    }\n    LaundryBatch {\n        int batch_id PK\n        int user_id FK\n        string laundry_type\n        datetime created_at\n    }\n    LaundryBatchItem {\n        int batch_id FK\n        int item_id FK\n        int reset_to_score\n        datetime processed_at\n    }\n\n    User ||--o{ CalendarEvent : \"has\"\n    User ||--o{ ClothingItem : \"owns\"\n    User ||--o{ Outfit : \"generates\"\n    User ||--o{ WearEvent : \"logs\"\n    User ||--o{ LaundryBatch : \"creates\"\n\n    Category ||--o{ ClothingItem : \"classifies\"\n    Fabric ||--o{ ClothingItem : \"material of\"\n    Occasion ||--o{ CalendarEvent : \"typed as\"\n    Occasion ||--o{ Outfit : \"context of\"\n    Occasion ||--o{ WearEvent : \"context of\"\n    Occasion ||--o{ WearDegradeRule : \"adjusts\"\n\n    StyleTag ||--o{ ItemStyle : \"tagged to\"\n    StyleTag ||--o{ StyleOccasionFit : \"rated in\"\n    Occasion ||--o{ StyleOccasionFit : \"rates\"\n\n    ClothingItem ||--o{ ItemStyle : \"has\"\n    ClothingItem ||--o{ ItemColor : \"has\"\n    ClothingItem ||--o{ OutfitItem : \"included in\"\n    ClothingItem ||--o{ WearEventItem : \"tracked by\"\n    ClothingItem ||--o{ LaundryBatchItem : \"washed in\"\n\n    Color ||--o{ ItemColor : \"used in\"\n\n    WeatherSnapshot ||--o{ Outfit : \"context of\"\n    WeatherSnapshot ||--o{ WearEvent : \"context of\"\n    WeatherCondition ||--o{ WearDegradeRule : \"adjusts\"\n\n    Outfit ||--o{ OutfitItem : \"contains\"\n    Outfit ||--o{ WearEvent : \"confirmed by\"\n\n    Category ||--o{ WearDegradeRule : \"base of\"\n    WearEvent ||--o{ WearEventItem : \"details\"\n    LaundryBatch ||--o{ LaundryBatchItem : \"includes\"\n\n\n\n\n\n\n\n\n\n\n\n\n基礎查找表，供其他表透過 FK 引用。獨立成表以避免重複資料，並方便統一維護。\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nuser_id\nINT\nPK\n使用者唯一識別碼\n\n\nname\nVARCHAR\nNOT NULL\n使用者名稱\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ncategory_id\nINT\nPK\n類別識別碼\n\n\nname\nVARCHAR\nNOT NULL\n衣物類別，如 top、bottom、shoes、outerwear、accessory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ncolor_id\nINT\nPK\n顏色識別碼\n\n\nname\nVARCHAR\nNOT NULL\n顏色名稱，如 black、white、navy、grey、beige\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nfabric_id\nINT\nPK\n布料識別碼\n\n\nname\nVARCHAR\nNOT NULL\n布料名稱，如 wool、cotton、linen\n\n\nwarmth_weight\nINT\n0–100\n保暖度，wool=90、cotton=50、linen=20\n\n\nbreathability\nINT\n0–100\n透氣度\n\n\n\n\nFabric 獨立成表的理由：每件衣物不需重複輸入布料屬性，保暖度和透氣度可直接用於天氣過濾和穿搭評分。\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nstyle_id\nINT\nPK\n風格識別碼\n\n\nname\nVARCHAR\nNOT NULL\n風格名稱，如 street、semi-formal、formal、clean fit、simple\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\noccasion_id\nINT\nPK\n場合識別碼\n\n\nname\nVARCHAR\nNOT NULL\n場合名稱，如 job interview、casual outing\n\n\ntarget_formality_min\nINT\n0–100\n場合要求的最低正式度\n\n\ntarget_formality_max\nINT\n0–100\n場合要求的最高正式度\n\n\n\n\n\n\n\n\n記錄每種風格在各場合的適配分數，讓推薦引擎能根據今日場合自動過濾不適合的穿搭風格。\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nstyle_id\nINT\nPK, FK → StyleTag\n風格\n\n\noccasion_id\nINT\nPK, FK → Occasion\n場合\n\n\nfit_score\nINT\n0–100\n適配分數，如 street + 面試 = 10、semi-formal + 面試 = 90\n\n\n\n\n\n\n\n\n系統自動讀取今日行程並對應到場合，省去每天手動選擇場合的步驟。\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nevent_id\nINT\nPK\n行程識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\nevent_name\nVARCHAR\nNOT NULL\n行程名稱\n\n\noccasion_id\nINT\nFK → Occasion\n對應場合\n\n\nevent_date\nDATE\nNOT NULL\n日期\n\n\nstart_time\nTIME\nNOT NULL\n開始時間\n\n\n\n\n\n\n\n\n核心衣物資料表，記錄每件衣物的物理屬性、狀態，以及多對多的風格標籤。\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nitem_id\nINT\nPK\n衣物識別碼\n\n\nuser_id\nINT\nFK → User\n擁有者\n\n\ncategory_id\nINT\nFK → Category\n衣物類別\n\n\nfabric_id\nINT\nFK → Fabric\n布料\n\n\nbrand\nVARCHAR\n—\n品牌\n\n\nitem_name\nVARCHAR\nNOT NULL\n衣物名稱\n\n\nformality_score\nINT\n0–100\n正式度分數\n\n\nwarmth_score\nINT\n0–100\n保暖分數，結合 Fabric.warmth_weight 使用\n\n\nclean_score\nINT\n可為負數\n清潔度；可推薦條件：clean_score &gt; 0\n\n\nstatus\nENUM\nactive / in_laundry / archived\n衣物狀態；可推薦條件：status = 'active'\n\n\ncreated_at\nDATETIME\nNOT NULL\n建立時間\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\nstyle_id\nINT\nPK, FK → StyleTag\n風格標籤\n\n\n\n\n\n\n\n\n每件衣物最多三色，依角色區分（primary / secondary / accent），用於 60/30/10 配色理論評分。\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\ncolor_id\nINT\nPK, FK → Color\n顏色\n\n\nrole\nENUM\nPK; primary / secondary / accent\n顏色角色\n\n\n\n限制條件：\n\n每件衣物最多 3 筆（各角色各 1）\nprimary：必填，唯一\nsecondary：選填，最多 1 個\naccent：選填，最多 1 個\n\n範例：\n\n\n\n衣物\ncolor\nrole\n\n\n\n\n黑色素T\nblack\nprimary\n\n\nLiverpool 球衣\nred\nprimary\n\n\nLiverpool 球衣\nwhite\nsecondary\n\n\nAdidas 三線褲\nblack\nprimary\n\n\nAdidas 三線褲\nnavy\nsecondary\n\n\nAdidas 三線褲\nwhite\naccent\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nweather_id\nINT\nPK\n天氣快照識別碼\n\n\nlocation\nVARCHAR\nNOT NULL\n地點\n\n\ncaptured_at\nDATETIME\nNOT NULL\n擷取時間\n\n\ntemp_c\nFLOAT\n—\n實際溫度（°C）\n\n\nfeels_like_c\nFLOAT\n—\n體感溫度（°C）\n\n\nhumidity\nINT\n—\n濕度（%）\n\n\nwind_speed\nFLOAT\n—\n風速\n\n\nprecip_mm\nFLOAT\n—\n降水量（mm）\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ncondition_id\nINT\nPK\n天氣狀態識別碼\n\n\nname\nVARCHAR\nNOT NULL\n狀態名稱，如 cold_rainy、hot_humid\n\n\nmin_temp_c\nFLOAT\n—\n溫度下限\n\n\nmax_temp_c\nFLOAT\n—\n溫度上限\n\n\nmin_precip_mm\nFLOAT\n—\n降水下限\n\n\nmax_precip_mm\nFLOAT\n—\n降水上限\n\n\nmin_wind\nFLOAT\n—\n風速下限\n\n\nmax_wind\nFLOAT\n—\n風速上限\n\n\nmin_humidity\nFLOAT\n—\n濕度下限\n\n\nmax_humidity\nFLOAT\n—\n濕度上限\n\n\n\n\nWeatherCondition 用於分類天氣狀態，供 WearDegradeRule 規則匹配（例如：下雨天穿白鞋多扣分）。\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\noutfit_id\nINT\nPK\n穿搭識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\noccasion_id\nINT\nFK → Occasion\n場合\n\n\nweather_id\nINT\nFK → WeatherSnapshot\n天氣快照\n\n\ntotal_score\nFLOAT\n—\n穿搭總分\n\n\nexplanation\nTEXT\n—\n推薦說明\n\n\ncreated_at\nDATETIME\nNOT NULL\n建立時間\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\noutfit_id\nINT\nPK, FK → Outfit\n穿搭\n\n\nslot\nENUM\nPK; top / bottom / shoes / outerwear / accessory\n穿搭位置\n\n\nlayer_order\nINT\nPK; 1, 2, 3…\n層次順序，支援多層穿搭\n\n\nitem_id\nINT\nFK → ClothingItem\n衣物\n\n\n\n\n(outfit_id, slot, layer_order) 三欄聯合主鍵，支援同一 slot 不同層次（如外套 + 毛衣同為 outerwear，layer_order = 1, 2）。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nscore_rule_id\nINT\nPK\n規則識別碼\n\n\nname\nVARCHAR\nNOT NULL\n規則名稱\n\n\nrule_type\nENUM\ncolor_theory / fabric / style / formality / layering / misc\n規則類型\n\n\nscore_delta\nINT\n—\n分數加減值\n\n\nexplanation_template\nTEXT\n—\n說明模板（輸出推薦理由用）\n\n\ncondition_json\nJSON\n—\n結構化條件，方便擴充\n\n\nvalid_from\nDATE\nNOT NULL\n規則生效日期\n\n\nvalid_until\nDATE\nNULLABLE\n規則失效日期（NULL = 永久有效）\n\n\n\n\nvalid_from / valid_until 支援時效性規則，例如：2025 blokecore 流行 → 足球衣 + 寬褲加分，valid_until = 2025-12，流行退燒後自動失效，不需修改程式碼。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ndegrade_rule_id\nINT\nPK\n規則識別碼\n\n\ncategory_id\nINT\nFK → Category\n衣物類別（基礎扣分）\n\n\noccasion_id\nINT\nFK → Occasion, NULLABLE\n場合調整（可選）\n\n\ncondition_id\nINT\nFK → WeatherCondition, NULLABLE\n天氣調整（可選）\n\n\ndelta_clean_score\nINT\n負整數\n每次穿著的扣分值\n\n\n\n\n支援堆疊扣分：一次穿著可匹配多條規則（類別基礎 + 場合加減 + 天氣加減），加總後套用。\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nevent_id\nINT\nPK\n事件識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\noutfit_id\nINT\nFK → Outfit\n穿著的穿搭\n\n\noccasion_id\nINT\nFK → Occasion\n場合\n\n\nweather_id\nINT\nFK → WeatherSnapshot\n當日天氣\n\n\nworn_at\nDATETIME\nNOT NULL\n穿著時間\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nevent_id\nINT\nPK, FK → WearEvent\n穿著事件\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\ndelta_applied\nINT\n—\n實際套用的扣分值\n\n\nclean_score_after\nINT\n—\n扣分後的 clean_score\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nbatch_id\nINT\nPK\n洗衣批次識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\nlaundry_type\nENUM\ndark / light\n深色 / 淺色分類洗\n\n\ncreated_at\nDATETIME\nNOT NULL\n建立時間\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nbatch_id\nINT\nPK, FK → LaundryBatch\n洗衣批次\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\nreset_to_score\nINT\n= 100\n洗完後重設的 clean_score\n\n\nprocessed_at\nDATETIME\nNOT NULL\n洗完時間\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n設計決策\n說明\n\n\n\n\nFabric 獨立成表\n保暖度 (warmth_weight) 和透氣度 (breathability) 統一管理，每件衣物透過 FK 引用，不重複輸入。布料屬性可直接用於天氣過濾和評分加減。\n\n\nItemColor 三角色設計\n基於 60/30/10 配色理論，primary / secondary / accent 角色讓評分引擎能明確判斷整套穿搭的配色比例是否協調，而非只比對顏色有無。\n\n\nStyleOccasionFit\n明確記錄風格與場合的適配分數，讓系統在篩選穿搭時能自動排除風格不合場合的組合，不需 hard-code 邏輯。\n\n\nCalendarEvent 行事曆整合\n自動對應今日行程到場合，省去每天手動選擇，降低使用門檻。\n\n\nOutfitScoringRule 規則表 + condition_json\n穿搭邏輯完全由資料驅動，修改評分規則只需編輯資料，不需改程式碼。condition_json 保持結構靈活，方便未來新增複雜條件。\n\n\nvalid_from / valid_until\n支援時效性流行趨勢規則（如 blokecore 2025），規則過期自動失效，維護成本低。\n\n\nWearDegradeRule 堆疊扣分\n一次穿著可同時匹配類別基礎規則、場合調整規則和天氣調整規則，加總扣分，比單一固定值更精確反映實際磨損。\n\n\nWearEvent / WearEventItem 事件紀錄\n保留完整歷史穿著紀錄，每次扣分前後都有快照，提供可追溯性，也為未來偏好學習提供訓練資料。\n\n\n\n\n\n\n\n\n多人支援：共享衣櫃、借衣功能，User 表已預留擴充空間。\n精確配色：加入 HEX / RGB 色碼欄位，配合色彩距離演算法提升配色判斷精確度。\n偏好學習：以 WearEvent 歷史資料訓練排序模型，從規則推薦進化到 AI 個人化推薦。"
  },
  {
    "objectID": "EPPS6354_project.html#weather--and-occasion-aware-wardrobe-database-with-rule-based-outfit-recommendation",
    "href": "EPPS6354_project.html#weather--and-occasion-aware-wardrobe-database-with-rule-based-outfit-recommendation",
    "title": "Wardrobe Database — Final Project",
    "section": "",
    "text": "This project builds a single-user wardrobe management database whose primary goal is outfit recommendation. Each morning, the system reads the user’s calendar (to determine the occasion) and the current weather, filters out unwearable items (dirty or archived), and ranks candidate outfits using a rule-based scoring engine grounded in color theory, fabric compatibility, and style coherence. The output is the best recommended outfit plus 3–5 ranked alternatives, each with a score and a brief explanation.\nCore workflow:\nWake up → Read calendar (occasion) + weather → Filter wearable items → Score outfit combinations → Output recommendation\nThree scoring dimensions:\n\nColor — 60/30/10 color theory; each item carries a primary / secondary / accent color role, and the engine checks whether the combined outfit achieves a balanced palette.\nFabric — same-fabric bonus (suit effect), mixed-fabric reasonableness, and warmth adequacy relative to the weather.\nStyle — style-tag consistency across items, and style–occasion fit scores stored in StyleOccasionFit.\n\n\n\n\n\n\n\n\n\n\nerDiagram\n    User {\n        int user_id PK\n        string name\n    }\n    Category {\n        int category_id PK\n        string name\n    }\n    Color {\n        int color_id PK\n        string name\n    }\n    Fabric {\n        int fabric_id PK\n        string name\n        int warmth_weight\n        int breathability\n    }\n    StyleTag {\n        int style_id PK\n        string name\n    }\n    Occasion {\n        int occasion_id PK\n        string name\n        int target_formality_min\n        int target_formality_max\n    }\n    StyleOccasionFit {\n        int style_id FK\n        int occasion_id FK\n        int fit_score\n    }\n    CalendarEvent {\n        int event_id PK\n        int user_id FK\n        string event_name\n        int occasion_id FK\n        date event_date\n        time start_time\n    }\n    ClothingItem {\n        int item_id PK\n        int user_id FK\n        int category_id FK\n        int fabric_id FK\n        string brand\n        string item_name\n        int formality_score\n        int warmth_score\n        int clean_score\n        string status\n        datetime created_at\n    }\n    ItemStyle {\n        int item_id FK\n        int style_id FK\n    }\n    ItemColor {\n        int item_id FK\n        int color_id FK\n        string role\n    }\n    WeatherSnapshot {\n        int weather_id PK\n        string location\n        datetime captured_at\n        float temp_c\n        float feels_like_c\n        int humidity\n        float wind_speed\n        float precip_mm\n    }\n    WeatherCondition {\n        int condition_id PK\n        string name\n        float min_temp_c\n        float max_temp_c\n        float min_precip_mm\n        float max_precip_mm\n        float min_wind\n        float max_wind\n        float min_humidity\n        float max_humidity\n    }\n    Outfit {\n        int outfit_id PK\n        int user_id FK\n        int occasion_id FK\n        int weather_id FK\n        float total_score\n        string explanation\n        datetime created_at\n    }\n    OutfitItem {\n        int outfit_id FK\n        int item_id FK\n        string slot\n        int layer_order\n    }\n    OutfitScoringRule {\n        int score_rule_id PK\n        string name\n        string rule_type\n        int score_delta\n        string explanation_template\n        json condition_json\n        date valid_from\n        date valid_until\n    }\n    WearDegradeRule {\n        int degrade_rule_id PK\n        int category_id FK\n        int occasion_id FK\n        int condition_id FK\n        int delta_clean_score\n    }\n    WearEvent {\n        int event_id PK\n        int user_id FK\n        int outfit_id FK\n        int occasion_id FK\n        int weather_id FK\n        datetime worn_at\n    }\n    WearEventItem {\n        int event_id FK\n        int item_id FK\n        int delta_applied\n        int clean_score_after\n    }\n    LaundryBatch {\n        int batch_id PK\n        int user_id FK\n        string laundry_type\n        datetime created_at\n    }\n    LaundryBatchItem {\n        int batch_id FK\n        int item_id FK\n        int reset_to_score\n        datetime processed_at\n    }\n\n    User ||--o{ CalendarEvent : \"has\"\n    User ||--o{ ClothingItem : \"owns\"\n    User ||--o{ Outfit : \"generates\"\n    User ||--o{ WearEvent : \"logs\"\n    User ||--o{ LaundryBatch : \"creates\"\n\n    Category ||--o{ ClothingItem : \"classifies\"\n    Fabric ||--o{ ClothingItem : \"material of\"\n    Occasion ||--o{ CalendarEvent : \"typed as\"\n    Occasion ||--o{ Outfit : \"context of\"\n    Occasion ||--o{ WearEvent : \"context of\"\n    Occasion ||--o{ WearDegradeRule : \"adjusts\"\n\n    StyleTag ||--o{ ItemStyle : \"tagged to\"\n    StyleTag ||--o{ StyleOccasionFit : \"rated in\"\n    Occasion ||--o{ StyleOccasionFit : \"rates\"\n\n    ClothingItem ||--o{ ItemStyle : \"has\"\n    ClothingItem ||--o{ ItemColor : \"has\"\n    ClothingItem ||--o{ OutfitItem : \"included in\"\n    ClothingItem ||--o{ WearEventItem : \"tracked by\"\n    ClothingItem ||--o{ LaundryBatchItem : \"washed in\"\n\n    Color ||--o{ ItemColor : \"used in\"\n\n    WeatherSnapshot ||--o{ Outfit : \"context of\"\n    WeatherSnapshot ||--o{ WearEvent : \"context of\"\n    WeatherCondition ||--o{ WearDegradeRule : \"adjusts\"\n\n    Outfit ||--o{ OutfitItem : \"contains\"\n    Outfit ||--o{ WearEvent : \"confirmed by\"\n\n    Category ||--o{ WearDegradeRule : \"base of\"\n    WearEvent ||--o{ WearEventItem : \"details\"\n    LaundryBatch ||--o{ LaundryBatchItem : \"includes\"\n\n\n\n\n\n\n\n\n\n\n\n\n基礎查找表，供其他表透過 FK 引用。獨立成表以避免重複資料，並方便統一維護。\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nuser_id\nINT\nPK\n使用者唯一識別碼\n\n\nname\nVARCHAR\nNOT NULL\n使用者名稱\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ncategory_id\nINT\nPK\n類別識別碼\n\n\nname\nVARCHAR\nNOT NULL\n衣物類別，如 top、bottom、shoes、outerwear、accessory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ncolor_id\nINT\nPK\n顏色識別碼\n\n\nname\nVARCHAR\nNOT NULL\n顏色名稱，如 black、white、navy、grey、beige\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nfabric_id\nINT\nPK\n布料識別碼\n\n\nname\nVARCHAR\nNOT NULL\n布料名稱，如 wool、cotton、linen\n\n\nwarmth_weight\nINT\n0–100\n保暖度，wool=90、cotton=50、linen=20\n\n\nbreathability\nINT\n0–100\n透氣度\n\n\n\n\nFabric 獨立成表的理由：每件衣物不需重複輸入布料屬性，保暖度和透氣度可直接用於天氣過濾和穿搭評分。\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nstyle_id\nINT\nPK\n風格識別碼\n\n\nname\nVARCHAR\nNOT NULL\n風格名稱，如 street、semi-formal、formal、clean fit、simple\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\noccasion_id\nINT\nPK\n場合識別碼\n\n\nname\nVARCHAR\nNOT NULL\n場合名稱，如 job interview、casual outing\n\n\ntarget_formality_min\nINT\n0–100\n場合要求的最低正式度\n\n\ntarget_formality_max\nINT\n0–100\n場合要求的最高正式度\n\n\n\n\n\n\n\n\n記錄每種風格在各場合的適配分數，讓推薦引擎能根據今日場合自動過濾不適合的穿搭風格。\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nstyle_id\nINT\nPK, FK → StyleTag\n風格\n\n\noccasion_id\nINT\nPK, FK → Occasion\n場合\n\n\nfit_score\nINT\n0–100\n適配分數，如 street + 面試 = 10、semi-formal + 面試 = 90\n\n\n\n\n\n\n\n\n系統自動讀取今日行程並對應到場合，省去每天手動選擇場合的步驟。\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nevent_id\nINT\nPK\n行程識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\nevent_name\nVARCHAR\nNOT NULL\n行程名稱\n\n\noccasion_id\nINT\nFK → Occasion\n對應場合\n\n\nevent_date\nDATE\nNOT NULL\n日期\n\n\nstart_time\nTIME\nNOT NULL\n開始時間\n\n\n\n\n\n\n\n\n核心衣物資料表，記錄每件衣物的物理屬性、狀態，以及多對多的風格標籤。\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nitem_id\nINT\nPK\n衣物識別碼\n\n\nuser_id\nINT\nFK → User\n擁有者\n\n\ncategory_id\nINT\nFK → Category\n衣物類別\n\n\nfabric_id\nINT\nFK → Fabric\n布料\n\n\nbrand\nVARCHAR\n—\n品牌\n\n\nitem_name\nVARCHAR\nNOT NULL\n衣物名稱\n\n\nformality_score\nINT\n0–100\n正式度分數\n\n\nwarmth_score\nINT\n0–100\n保暖分數，結合 Fabric.warmth_weight 使用\n\n\nclean_score\nINT\n可為負數\n清潔度；可推薦條件：clean_score &gt; 0\n\n\nstatus\nENUM\nactive / in_laundry / archived\n衣物狀態；可推薦條件：status = 'active'\n\n\ncreated_at\nDATETIME\nNOT NULL\n建立時間\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\nstyle_id\nINT\nPK, FK → StyleTag\n風格標籤\n\n\n\n\n\n\n\n\n每件衣物最多三色，依角色區分（primary / secondary / accent），用於 60/30/10 配色理論評分。\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\ncolor_id\nINT\nPK, FK → Color\n顏色\n\n\nrole\nENUM\nPK; primary / secondary / accent\n顏色角色\n\n\n\n限制條件：\n\n每件衣物最多 3 筆（各角色各 1）\nprimary：必填，唯一\nsecondary：選填，最多 1 個\naccent：選填，最多 1 個\n\n範例：\n\n\n\n衣物\ncolor\nrole\n\n\n\n\n黑色素T\nblack\nprimary\n\n\nLiverpool 球衣\nred\nprimary\n\n\nLiverpool 球衣\nwhite\nsecondary\n\n\nAdidas 三線褲\nblack\nprimary\n\n\nAdidas 三線褲\nnavy\nsecondary\n\n\nAdidas 三線褲\nwhite\naccent\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nweather_id\nINT\nPK\n天氣快照識別碼\n\n\nlocation\nVARCHAR\nNOT NULL\n地點\n\n\ncaptured_at\nDATETIME\nNOT NULL\n擷取時間\n\n\ntemp_c\nFLOAT\n—\n實際溫度（°C）\n\n\nfeels_like_c\nFLOAT\n—\n體感溫度（°C）\n\n\nhumidity\nINT\n—\n濕度（%）\n\n\nwind_speed\nFLOAT\n—\n風速\n\n\nprecip_mm\nFLOAT\n—\n降水量（mm）\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ncondition_id\nINT\nPK\n天氣狀態識別碼\n\n\nname\nVARCHAR\nNOT NULL\n狀態名稱，如 cold_rainy、hot_humid\n\n\nmin_temp_c\nFLOAT\n—\n溫度下限\n\n\nmax_temp_c\nFLOAT\n—\n溫度上限\n\n\nmin_precip_mm\nFLOAT\n—\n降水下限\n\n\nmax_precip_mm\nFLOAT\n—\n降水上限\n\n\nmin_wind\nFLOAT\n—\n風速下限\n\n\nmax_wind\nFLOAT\n—\n風速上限\n\n\nmin_humidity\nFLOAT\n—\n濕度下限\n\n\nmax_humidity\nFLOAT\n—\n濕度上限\n\n\n\n\nWeatherCondition 用於分類天氣狀態，供 WearDegradeRule 規則匹配（例如：下雨天穿白鞋多扣分）。\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\noutfit_id\nINT\nPK\n穿搭識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\noccasion_id\nINT\nFK → Occasion\n場合\n\n\nweather_id\nINT\nFK → WeatherSnapshot\n天氣快照\n\n\ntotal_score\nFLOAT\n—\n穿搭總分\n\n\nexplanation\nTEXT\n—\n推薦說明\n\n\ncreated_at\nDATETIME\nNOT NULL\n建立時間\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\noutfit_id\nINT\nPK, FK → Outfit\n穿搭\n\n\nslot\nENUM\nPK; top / bottom / shoes / outerwear / accessory\n穿搭位置\n\n\nlayer_order\nINT\nPK; 1, 2, 3…\n層次順序，支援多層穿搭\n\n\nitem_id\nINT\nFK → ClothingItem\n衣物\n\n\n\n\n(outfit_id, slot, layer_order) 三欄聯合主鍵，支援同一 slot 不同層次（如外套 + 毛衣同為 outerwear，layer_order = 1, 2）。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nscore_rule_id\nINT\nPK\n規則識別碼\n\n\nname\nVARCHAR\nNOT NULL\n規則名稱\n\n\nrule_type\nENUM\ncolor_theory / fabric / style / formality / layering / misc\n規則類型\n\n\nscore_delta\nINT\n—\n分數加減值\n\n\nexplanation_template\nTEXT\n—\n說明模板（輸出推薦理由用）\n\n\ncondition_json\nJSON\n—\n結構化條件，方便擴充\n\n\nvalid_from\nDATE\nNOT NULL\n規則生效日期\n\n\nvalid_until\nDATE\nNULLABLE\n規則失效日期（NULL = 永久有效）\n\n\n\n\nvalid_from / valid_until 支援時效性規則，例如：2025 blokecore 流行 → 足球衣 + 寬褲加分，valid_until = 2025-12，流行退燒後自動失效，不需修改程式碼。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\ndegrade_rule_id\nINT\nPK\n規則識別碼\n\n\ncategory_id\nINT\nFK → Category\n衣物類別（基礎扣分）\n\n\noccasion_id\nINT\nFK → Occasion, NULLABLE\n場合調整（可選）\n\n\ncondition_id\nINT\nFK → WeatherCondition, NULLABLE\n天氣調整（可選）\n\n\ndelta_clean_score\nINT\n負整數\n每次穿著的扣分值\n\n\n\n\n支援堆疊扣分：一次穿著可匹配多條規則（類別基礎 + 場合加減 + 天氣加減），加總後套用。\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nevent_id\nINT\nPK\n事件識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\noutfit_id\nINT\nFK → Outfit\n穿著的穿搭\n\n\noccasion_id\nINT\nFK → Occasion\n場合\n\n\nweather_id\nINT\nFK → WeatherSnapshot\n當日天氣\n\n\nworn_at\nDATETIME\nNOT NULL\n穿著時間\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nevent_id\nINT\nPK, FK → WearEvent\n穿著事件\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\ndelta_applied\nINT\n—\n實際套用的扣分值\n\n\nclean_score_after\nINT\n—\n扣分後的 clean_score\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nbatch_id\nINT\nPK\n洗衣批次識別碼\n\n\nuser_id\nINT\nFK → User\n使用者\n\n\nlaundry_type\nENUM\ndark / light\n深色 / 淺色分類洗\n\n\ncreated_at\nDATETIME\nNOT NULL\n建立時間\n\n\n\n\n\n\n\n\n\nColumn\nType\nConstraint\nDescription\n\n\n\n\nbatch_id\nINT\nPK, FK → LaundryBatch\n洗衣批次\n\n\nitem_id\nINT\nPK, FK → ClothingItem\n衣物\n\n\nreset_to_score\nINT\n= 100\n洗完後重設的 clean_score\n\n\nprocessed_at\nDATETIME\nNOT NULL\n洗完時間\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n設計決策\n說明\n\n\n\n\nFabric 獨立成表\n保暖度 (warmth_weight) 和透氣度 (breathability) 統一管理，每件衣物透過 FK 引用，不重複輸入。布料屬性可直接用於天氣過濾和評分加減。\n\n\nItemColor 三角色設計\n基於 60/30/10 配色理論，primary / secondary / accent 角色讓評分引擎能明確判斷整套穿搭的配色比例是否協調，而非只比對顏色有無。\n\n\nStyleOccasionFit\n明確記錄風格與場合的適配分數，讓系統在篩選穿搭時能自動排除風格不合場合的組合，不需 hard-code 邏輯。\n\n\nCalendarEvent 行事曆整合\n自動對應今日行程到場合，省去每天手動選擇，降低使用門檻。\n\n\nOutfitScoringRule 規則表 + condition_json\n穿搭邏輯完全由資料驅動，修改評分規則只需編輯資料，不需改程式碼。condition_json 保持結構靈活，方便未來新增複雜條件。\n\n\nvalid_from / valid_until\n支援時效性流行趨勢規則（如 blokecore 2025），規則過期自動失效，維護成本低。\n\n\nWearDegradeRule 堆疊扣分\n一次穿著可同時匹配類別基礎規則、場合調整規則和天氣調整規則，加總扣分，比單一固定值更精確反映實際磨損。\n\n\nWearEvent / WearEventItem 事件紀錄\n保留完整歷史穿著紀錄，每次扣分前後都有快照，提供可追溯性，也為未來偏好學習提供訓練資料。\n\n\n\n\n\n\n\n\n多人支援：共享衣櫃、借衣功能，User 表已預留擴充空間。\n精確配色：加入 HEX / RGB 色碼欄位，配合色彩距離演算法提升配色判斷精確度。\n偏好學習：以 WearEvent 歷史資料訓練排序模型，從規則推薦進化到 AI 個人化推薦。"
  },
  {
    "objectID": "EPPS6354.html#final-project",
    "href": "EPPS6354.html#final-project",
    "title": "Information Management",
    "section": "Final Project",
    "text": "Final Project\n\nWeather- and Occasion-Aware Wardrobe Database with Rule-Based Outfit Recommendation\n\nProject Overview\nA single-user wardrobe management system. Each morning, the system reads the user’s calendar (to determine the occasion) and the current weather, filters out unwearable items (dirty or archived), and ranks candidate outfits using a rule-based scoring engine built on color theory, fabric compatibility, and style coherence. The output is the best recommended outfit plus 3–5 ranked alternatives, each with a score and explanation.\nCore workflow: Wake up → Read calendar (occasion) + weather → Filter wearable items → Score outfit combinations → Output recommendation\nThree scoring dimensions:\n\nColor — 60/30/10 color theory; each item carries a primary / secondary / accent color role\nFabric — same-fabric bonus, mixed-fabric reasonableness, warmth adequacy relative to weather\nStyle — style-tag consistency across items, and style–occasion fit scores\n\n\n\nDatabase Tables\n\nReference Tables\n\n\n\n\n\n\n\n\nTable\nKey Columns\nDescription\n\n\n\n\nUser\nuser_id PK, name\nStores user identity\n\n\nCategory\ncategory_id PK, name\nClothing categories: top, bottom, shoes, outerwear, accessory\n\n\nColor\ncolor_id PK, name\nColor names (black, white, navy, grey, beige…)\n\n\nFabric\nfabric_id PK, name, warmth_weight, breathability\nFabric type with warmth (0–100) and breathability (0–100) ratings\n\n\nStyleTag\nstyle_id PK, name\nStyle labels: street, formal, clean fit, simple, blokecore…\n\n\nOccasion\noccasion_id PK, name, target_formality_min, target_formality_max\nOccasion with required formality range\n\n\n\n\n\nStyle & Calendar\n\n\n\n\n\n\n\n\nTable\nKey Columns\nDescription\n\n\n\n\nStyleOccasionFit\nstyle_id FK, occasion_id FK, fit_score\nFit score (0–100) between a style and an occasion (PK: style_id + occasion_id)\n\n\nCalendarEvent\nevent_id PK, user_id FK, occasion_id FK, event_date, start_time\nCalendar entry mapped to an occasion; drives automatic occasion detection\n\n\n\n\n\nClothing Item & Tags\n\n\n\n\n\n\n\n\nTable\nKey Columns\nDescription\n\n\n\n\nClothingItem\nitem_id PK, user_id FK, category_id FK, fabric_id FK, formality_score, warmth_score, clean_score, status\nMain clothing table; recommendable only if clean_score &gt; 0 and status = 'active'\n\n\nItemStyle\nitem_id FK, style_id FK\nMany-to-many: clothing item to style tags\n\n\nItemColor\nitem_id FK, color_id FK, role (primary/secondary/accent)\nColor role assignment per item; max 3 colors per item\n\n\n\n\n\nWeather\n\n\n\n\n\n\n\n\nTable\nKey Columns\nDescription\n\n\n\n\nWeatherSnapshot\nweather_id PK, location, temp_c, feels_like_c, humidity, wind_speed, precip_mm\nReal-time weather data snapshot\n\n\nWeatherCondition\ncondition_id PK, name, temp/precip/wind/humidity ranges\nNamed weather condition (e.g. cold_rainy, hot_humid) used for rule matching\n\n\n\n\n\nOutfit\n\n\n\n\n\n\n\n\nTable\nKey Columns\nDescription\n\n\n\n\nOutfit\noutfit_id PK, user_id FK, occasion_id FK, weather_id FK, total_score, explanation\nGenerated outfit with total score and explanation\n\n\nOutfitItem\nPK(outfit_id, slot, layer_order), item_id FK\nOutfit detail; supports multi-layer dressing within the same slot\n\n\n\n\n\nScoring Rules\n\n\n\n\n\n\n\n\nTable\nKey Columns\nDescription\n\n\n\n\nOutfitScoringRule\nscore_rule_id PK, rule_type, score_delta, condition_json, valid_from, valid_until\nScoring rule with optional expiry date to support trend-based rules\n\n\nWearDegradeRule\ndegrade_rule_id PK, category_id FK, occasion_id FK (nullable), condition_id FK (nullable), delta_clean_score\nClean score deduction rule; multiple matching rules are stacked per wear event\n\n\n\n\n\nWear Tracking & Laundry\n\n\n\n\n\n\n\n\nTable\nKey Columns\nDescription\n\n\n\n\nWearEvent\nevent_id PK, user_id FK, outfit_id FK, occasion_id FK, weather_id FK, worn_at\nRecords each time an outfit is worn\n\n\nWearEventItem\nPK(event_id, item_id), delta_applied, clean_score_after\nPer-item deduction detail and resulting clean score after wear\n\n\nLaundryBatch\nbatch_id PK, user_id FK, laundry_type (dark/light)\nLaundry batch grouped by color type\n\n\nLaundryBatchItem\nPK(batch_id, item_id), reset_to_score = 100\nResets clean score to 100 upon laundering"
  },
  {
    "objectID": "ML.html",
    "href": "ML.html",
    "title": "Machine Learning & Data Science",
    "section": "",
    "text": "Task / 任務： Predict the onset of diabetes using the Pima Indians Diabetes dataset, with a focus on handling missing values through regression-based imputation, feature engineering, and resampling before training a deep neural network. 以 Pima Indians 糖尿病資料集為基礎，先用迴歸填補缺失值、進行特徵工程與資料重抽樣，再訓練深層神經網路進行二元分類。\nDataset / 資料集： Pima Indians Diabetes Dataset — 768 samples, 8 features\nMethod / 方法： Regression imputation → Feature engineering → Resampling → DNN\n\n\n\n\n\n\n\nflowchart LR\n    A[\"Raw Data\\n768 samples\\n8 features\"] --&gt; B[\"Treat zeros\\nas missing\"]\n    B --&gt; C[\"Regression\\nImputation\\n(5 features)\"]\n    C --&gt; D[\"Feature\\nEngineering\\n+ Resampling\"]\n    D --&gt; E[\"Train / Val\\nSplit\"]\n    E --&gt; F[\"DNN\\n64→32→16→1\"]\n    F --&gt; G[\"Binary\\nClassification\\n90.04% acc\"]\n\n    style A fill:#e8f4f8,stroke:#2196F3\n    style G fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nZero values in Glucose, BMI, BloodPressure, SkinThickness, and Insulin are treated as missing. After removing rows with missing values, 336 clean rows remain for fitting imputation models. 將 Glucose、BMI 等欄位的零值視為缺失。移除含缺失值的列後，336 筆乾淨資料用於訓練填補模型。\n\n\n\nFeature Correlation Matrix (after removing rows with NaN) — Glucose–Outcome (0.50) and SkinThickness–BMI (0.71) show the strongest correlations / 特徵相關矩陣：Glucose 與 Outcome 相關最高（0.50），SkinThickness 與 BMI 相關最強（0.71）\n\n\nKey observations / 重要觀察：\n\nGlucose → Outcome correlation: 0.50 — strongest predictor of diabetes\nSkinThickness ↔︎ BMI: 0.71 — justifies using BMI to impute SkinThickness\nInsulin ↔︎ Glucose: 0.70 — justifies using Glucose to impute Insulin\nAge ↔︎ Pregnancies: 0.54 — expected biological relationship\n\n\n\n\n\n\n\n\n\nflowchart TD\n    A[\"Outcome\"] --&gt;|\"predicts\"| B[\"Glucose\"]\n    B --&gt;|\"predicts\"| C[\"BMI\"]\n    B --&gt;|\"predicts\"| D[\"Insulin\"]\n    C & B --&gt;|\"predict\"| E[\"SkinThickness\"]\n    F[\"Age\"] & C --&gt;|\"predict\"| G[\"BloodPressure\"]\n\n    style A fill:#fff3e0,stroke:#FF9800\n    style B fill:#e3f2fd,stroke:#2196F3\n    style C fill:#e8f5e9,stroke:#4CAF50\n    style D fill:#fce4ec,stroke:#E91E63\n    style E fill:#f3e5f5,stroke:#9C27B0\n    style F fill:#fff3e0,stroke:#FF9800\n    style G fill:#e0f7fa,stroke:#00BCD4\n\n\n\n\n\n\n# Fill Glucose using Outcome\nX_train = df_non_missing[['Outcome']]\ny_train = df_non_missing['Glucose']\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Fill BMI using Glucose\nX_train = df_non_missing[['Glucose']]\ny_train = df_non_missing['BMI']\n\n# Fill Insulin using BMI + Glucose\nX_train = df_non_missing[['BMI', 'Glucose']]\ny_train = df_non_missing['Insulin']\n\n# Fill BloodPressure using Age + BMI\nX_train = df_non_missing[['Age', 'BMI']]\ny_train = df_non_missing['BloodPressure']\n\n\n\n\n\n\n\n\nflowchart LR\n    I[\"Input\\n8+ features\"] --&gt; L1[\"Dense 64\\nReLU\"]\n    L1 --&gt; L2[\"Dense 32\\nReLU\"]\n    L2 --&gt; L3[\"Dense 16\\nReLU\"]\n    L3 --&gt; O[\"Dense 1\\nSigmoid\\n→ Diabetes?\"]\n\n    style I fill:#e8f4f8,stroke:#2196F3\n    style O fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nBaseline accuracy (no imputation)\n74.03%\n\n\nFinal accuracy (with imputation + feature engineering + resampling)\n90.04%\n\n\nImprovement\n+16.01 pp\n\n\n\n\n\n\n\n\nAccuracy improvement across pipeline stages / 各階段準確率提升\n\n\n\n\n\n\n\n\n\nTask / 任務： Analyze 1.88 million US wildfire records to model annual frequency trends using Poisson regression, and predict wildfire causes using a multi-layer perceptron. 分析 188 萬筆美國野火紀錄，用 Poisson 迴歸建立年度頻率趨勢模型，並以 MLP 預測野火成因。\nDataset / 資料集： US Wildfires (1992–2015) — 1,880,465 records, Kaggle\nMethod / 方法： Poisson Regression (trend analysis) + MLP (cause classification)\n\n\nModels the annual count of wildfires as a function of year to estimate long-term trend. 建立野火年度數量對年份的 Poisson 迴歸，估計長期增長趨勢。\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\npoisson_model = smf.glm(\n    formula='Count ~ FIRE_YEAR',\n    data=fire_counts,\n    family=sm.families.Poisson()\n).fit()\n\nprint(poisson_model.summary())\n\n\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 24180 (\\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 20221 (\\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 21315 (\\N{CJK UNIFIED IDEOGRAPH-5343}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 20214 (\\N{CJK UNIFIED IDEOGRAPH-4EF6}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 21315 (\\N{CJK UNIFIED IDEOGRAPH-5343}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20214 (\\N{CJK UNIFIED IDEOGRAPH-4EF6}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24180 (\\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20221 (\\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\nEstimated Annual Wildfire Frequency Trend (Poisson Regression, +0.44%/yr) / 美國野火年度頻率趨勢\n\n\n\n\n\n\n\nFeatures: FIRE_SIZE, LATITUDE, LONGITUDE, FIRE_YEAR, MONTH\n\n\n\n\n\nflowchart LR\n    F[\"5 Features\\nFIRE_SIZE\\nLAT / LON\\nYEAR / MONTH\"] --&gt; D1[\"Dense 64\\nReLU\"]\n    D1 --&gt; DR1[\"Dropout 0.3\"]\n    DR1 --&gt; D2[\"Dense 64\\nReLU\"]\n    D2 --&gt; DR2[\"Dropout 0.3\"]\n    DR2 --&gt; O[\"Dense N\\nSoftmax\\n→ Cause Class\"]\n\n    style F fill:#e8f4f8,stroke:#2196F3\n    style O fill:#e8f8e8,stroke:#4CAF50\n    style DR1 fill:#fff3e0,stroke:#FF9800\n    style DR2 fill:#fff3e0,stroke:#FF9800\n\n\n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\n\n\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n# Train/Test Split: 70/30\n\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nWildfire cause prediction accuracy\n~45.6%\n\n\nPoisson regression trend\n+0.44% annual increase in wildfire frequency\n\n\nTotal records processed\n1,880,465\n\n\n\nThe relatively low classification accuracy reflects the inherent difficulty of attributing wildfire causes from geographic and temporal features alone. 分類準確率偏低，反映了僅依靠地理與時間特徵來判斷野火成因的固有難度。\n\n\n\n\n\nWildfire Cause Distribution & MLP Accuracy vs. Baseline / 野火成因分布與模型準確率比較\n\n\n\n\n\n\n\n\n\nTask / 任務： Classify cervical cell images into three types (Type 1, 2, 3) corresponding to different levels of cervical transformation zone, using transfer learning with EfficientNet-B7 and Focal Loss to handle class imbalance. 將子宮頸細胞影像分類為三種類型（Type 1/2/3），對應不同程度的子宮頸轉化帶，採用 EfficientNet-B7 遷移學習並以 Focal Loss 處理類別不平衡。\nDataset / 資料集： Intel & MobileODT Cervical Cancer Screening (Kaggle) — 3-class image classification\nMethod / 方法： EfficientNet-B7 (ImageNet pretrained, fine-tuned) + Focal Loss + Data Augmentation\n\n\n\n\n\n\n\nflowchart LR\n    A[\"ImageNet\\nPretrained\\nEfficientNet-B7\"] --&gt; B[\"Frozen\\nBackbone\\n(feature extraction)\"]\n    B --&gt; C[\"Custom\\nClassifier Head\\nLinear → 3 classes\"]\n    C --&gt; D[\"Fine-tune with\\nFocal Loss\\n(α=1, γ=2)\"]\n    D --&gt; E[\"Type 1 / 2 / 3\\nPrediction\"]\n\n    style A fill:#e3f2fd,stroke:#2196F3\n    style D fill:#fff3e0,stroke:#FF9800\n    style E fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nfrom torchvision.models import efficientnet_b7, EfficientNet_B7_Weights\n\nmodel = efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1)\nnum_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_features, num_classes)  # num_classes = 3\nmodel = model.to(device)\n\n\n\nFocal Loss down-weights easy examples and focuses training on hard, misclassified samples — especially useful for imbalanced class distributions. Focal Loss 降低簡單樣本的權重，讓訓練集中在難以分類的樣本，有效處理類別不平衡。\n\n\n\n\n\nFocal Loss vs. Cross-Entropy — γ=2 (used in this project) strongly down-weights easy examples / Focal Loss 與交叉熵損失比較\n\n\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        ce_loss = nn.CrossEntropyLoss(reduction=\"none\")(inputs, targets)\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        if self.reduction == \"mean\":\n            return focal_loss.mean()\n        elif self.reduction == \"sum\":\n            return focal_loss.sum()\n        return focal_loss\n\ncriterion = FocalLoss(alpha=1, gamma=2)\n\n\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nnum_epochs = 20\nbatch_size = 32\n\nfor epoch in range(num_epochs):\n    model.train()\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n\n\n\n\n\nClass\nDescription\nAccuracy\n\n\n\n\nType 1\nEctocervix (fully visible transformation zone)\n87.5%\n\n\nType 2\nPartially visible transformation zone\n92.3%\n\n\nType 3\nEndocervix (transformation zone not visible)\n78.5%\n\n\n\n\n\n\n\n\nPer-class Accuracy — Cervical Cancer Screening (EfficientNet-B7) / 各類別分類準確率"
  },
  {
    "objectID": "ML.html#assignments-作業",
    "href": "ML.html#assignments-作業",
    "title": "Machine Learning & Data Science",
    "section": "",
    "text": "Task / 任務： Predict the onset of diabetes using the Pima Indians Diabetes dataset, with a focus on handling missing values through regression-based imputation, feature engineering, and resampling before training a deep neural network. 以 Pima Indians 糖尿病資料集為基礎，先用迴歸填補缺失值、進行特徵工程與資料重抽樣，再訓練深層神經網路進行二元分類。\nDataset / 資料集： Pima Indians Diabetes Dataset — 768 samples, 8 features\nMethod / 方法： Regression imputation → Feature engineering → Resampling → DNN\n\n\n\n\n\n\n\nflowchart LR\n    A[\"Raw Data\\n768 samples\\n8 features\"] --&gt; B[\"Treat zeros\\nas missing\"]\n    B --&gt; C[\"Regression\\nImputation\\n(5 features)\"]\n    C --&gt; D[\"Feature\\nEngineering\\n+ Resampling\"]\n    D --&gt; E[\"Train / Val\\nSplit\"]\n    E --&gt; F[\"DNN\\n64→32→16→1\"]\n    F --&gt; G[\"Binary\\nClassification\\n90.04% acc\"]\n\n    style A fill:#e8f4f8,stroke:#2196F3\n    style G fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nZero values in Glucose, BMI, BloodPressure, SkinThickness, and Insulin are treated as missing. After removing rows with missing values, 336 clean rows remain for fitting imputation models. 將 Glucose、BMI 等欄位的零值視為缺失。移除含缺失值的列後，336 筆乾淨資料用於訓練填補模型。\n\n\n\nFeature Correlation Matrix (after removing rows with NaN) — Glucose–Outcome (0.50) and SkinThickness–BMI (0.71) show the strongest correlations / 特徵相關矩陣：Glucose 與 Outcome 相關最高（0.50），SkinThickness 與 BMI 相關最強（0.71）\n\n\nKey observations / 重要觀察：\n\nGlucose → Outcome correlation: 0.50 — strongest predictor of diabetes\nSkinThickness ↔︎ BMI: 0.71 — justifies using BMI to impute SkinThickness\nInsulin ↔︎ Glucose: 0.70 — justifies using Glucose to impute Insulin\nAge ↔︎ Pregnancies: 0.54 — expected biological relationship\n\n\n\n\n\n\n\n\n\nflowchart TD\n    A[\"Outcome\"] --&gt;|\"predicts\"| B[\"Glucose\"]\n    B --&gt;|\"predicts\"| C[\"BMI\"]\n    B --&gt;|\"predicts\"| D[\"Insulin\"]\n    C & B --&gt;|\"predict\"| E[\"SkinThickness\"]\n    F[\"Age\"] & C --&gt;|\"predict\"| G[\"BloodPressure\"]\n\n    style A fill:#fff3e0,stroke:#FF9800\n    style B fill:#e3f2fd,stroke:#2196F3\n    style C fill:#e8f5e9,stroke:#4CAF50\n    style D fill:#fce4ec,stroke:#E91E63\n    style E fill:#f3e5f5,stroke:#9C27B0\n    style F fill:#fff3e0,stroke:#FF9800\n    style G fill:#e0f7fa,stroke:#00BCD4\n\n\n\n\n\n\n# Fill Glucose using Outcome\nX_train = df_non_missing[['Outcome']]\ny_train = df_non_missing['Glucose']\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Fill BMI using Glucose\nX_train = df_non_missing[['Glucose']]\ny_train = df_non_missing['BMI']\n\n# Fill Insulin using BMI + Glucose\nX_train = df_non_missing[['BMI', 'Glucose']]\ny_train = df_non_missing['Insulin']\n\n# Fill BloodPressure using Age + BMI\nX_train = df_non_missing[['Age', 'BMI']]\ny_train = df_non_missing['BloodPressure']\n\n\n\n\n\n\n\n\nflowchart LR\n    I[\"Input\\n8+ features\"] --&gt; L1[\"Dense 64\\nReLU\"]\n    L1 --&gt; L2[\"Dense 32\\nReLU\"]\n    L2 --&gt; L3[\"Dense 16\\nReLU\"]\n    L3 --&gt; O[\"Dense 1\\nSigmoid\\n→ Diabetes?\"]\n\n    style I fill:#e8f4f8,stroke:#2196F3\n    style O fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nBaseline accuracy (no imputation)\n74.03%\n\n\nFinal accuracy (with imputation + feature engineering + resampling)\n90.04%\n\n\nImprovement\n+16.01 pp\n\n\n\n\n\n\n\n\nAccuracy improvement across pipeline stages / 各階段準確率提升\n\n\n\n\n\n\n\n\n\nTask / 任務： Analyze 1.88 million US wildfire records to model annual frequency trends using Poisson regression, and predict wildfire causes using a multi-layer perceptron. 分析 188 萬筆美國野火紀錄，用 Poisson 迴歸建立年度頻率趨勢模型，並以 MLP 預測野火成因。\nDataset / 資料集： US Wildfires (1992–2015) — 1,880,465 records, Kaggle\nMethod / 方法： Poisson Regression (trend analysis) + MLP (cause classification)\n\n\nModels the annual count of wildfires as a function of year to estimate long-term trend. 建立野火年度數量對年份的 Poisson 迴歸，估計長期增長趨勢。\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\npoisson_model = smf.glm(\n    formula='Count ~ FIRE_YEAR',\n    data=fire_counts,\n    family=sm.families.Poisson()\n).fit()\n\nprint(poisson_model.summary())\n\n\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 24180 (\\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 20221 (\\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 21315 (\\N{CJK UNIFIED IDEOGRAPH-5343}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/var/folders/r1/kfhndv_10_j0xvscg29hsmcc0000gn/T/ipykernel_99367/3506093347.py:20: UserWarning: Glyph 20214 (\\N{CJK UNIFIED IDEOGRAPH-4EF6}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 21315 (\\N{CJK UNIFIED IDEOGRAPH-5343}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20214 (\\N{CJK UNIFIED IDEOGRAPH-4EF6}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24180 (\\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/Users/buttegg/.quarto-venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20221 (\\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\nEstimated Annual Wildfire Frequency Trend (Poisson Regression, +0.44%/yr) / 美國野火年度頻率趨勢\n\n\n\n\n\n\n\nFeatures: FIRE_SIZE, LATITUDE, LONGITUDE, FIRE_YEAR, MONTH\n\n\n\n\n\nflowchart LR\n    F[\"5 Features\\nFIRE_SIZE\\nLAT / LON\\nYEAR / MONTH\"] --&gt; D1[\"Dense 64\\nReLU\"]\n    D1 --&gt; DR1[\"Dropout 0.3\"]\n    DR1 --&gt; D2[\"Dense 64\\nReLU\"]\n    D2 --&gt; DR2[\"Dropout 0.3\"]\n    DR2 --&gt; O[\"Dense N\\nSoftmax\\n→ Cause Class\"]\n\n    style F fill:#e8f4f8,stroke:#2196F3\n    style O fill:#e8f8e8,stroke:#4CAF50\n    style DR1 fill:#fff3e0,stroke:#FF9800\n    style DR2 fill:#fff3e0,stroke:#FF9800\n\n\n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\n\n\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n# Train/Test Split: 70/30\n\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nWildfire cause prediction accuracy\n~45.6%\n\n\nPoisson regression trend\n+0.44% annual increase in wildfire frequency\n\n\nTotal records processed\n1,880,465\n\n\n\nThe relatively low classification accuracy reflects the inherent difficulty of attributing wildfire causes from geographic and temporal features alone. 分類準確率偏低，反映了僅依靠地理與時間特徵來判斷野火成因的固有難度。\n\n\n\n\n\nWildfire Cause Distribution & MLP Accuracy vs. Baseline / 野火成因分布與模型準確率比較\n\n\n\n\n\n\n\n\n\nTask / 任務： Classify cervical cell images into three types (Type 1, 2, 3) corresponding to different levels of cervical transformation zone, using transfer learning with EfficientNet-B7 and Focal Loss to handle class imbalance. 將子宮頸細胞影像分類為三種類型（Type 1/2/3），對應不同程度的子宮頸轉化帶，採用 EfficientNet-B7 遷移學習並以 Focal Loss 處理類別不平衡。\nDataset / 資料集： Intel & MobileODT Cervical Cancer Screening (Kaggle) — 3-class image classification\nMethod / 方法： EfficientNet-B7 (ImageNet pretrained, fine-tuned) + Focal Loss + Data Augmentation\n\n\n\n\n\n\n\nflowchart LR\n    A[\"ImageNet\\nPretrained\\nEfficientNet-B7\"] --&gt; B[\"Frozen\\nBackbone\\n(feature extraction)\"]\n    B --&gt; C[\"Custom\\nClassifier Head\\nLinear → 3 classes\"]\n    C --&gt; D[\"Fine-tune with\\nFocal Loss\\n(α=1, γ=2)\"]\n    D --&gt; E[\"Type 1 / 2 / 3\\nPrediction\"]\n\n    style A fill:#e3f2fd,stroke:#2196F3\n    style D fill:#fff3e0,stroke:#FF9800\n    style E fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nfrom torchvision.models import efficientnet_b7, EfficientNet_B7_Weights\n\nmodel = efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1)\nnum_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_features, num_classes)  # num_classes = 3\nmodel = model.to(device)\n\n\n\nFocal Loss down-weights easy examples and focuses training on hard, misclassified samples — especially useful for imbalanced class distributions. Focal Loss 降低簡單樣本的權重，讓訓練集中在難以分類的樣本，有效處理類別不平衡。\n\n\n\n\n\nFocal Loss vs. Cross-Entropy — γ=2 (used in this project) strongly down-weights easy examples / Focal Loss 與交叉熵損失比較\n\n\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        ce_loss = nn.CrossEntropyLoss(reduction=\"none\")(inputs, targets)\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        if self.reduction == \"mean\":\n            return focal_loss.mean()\n        elif self.reduction == \"sum\":\n            return focal_loss.sum()\n        return focal_loss\n\ncriterion = FocalLoss(alpha=1, gamma=2)\n\n\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nnum_epochs = 20\nbatch_size = 32\n\nfor epoch in range(num_epochs):\n    model.train()\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n\n\n\n\n\nClass\nDescription\nAccuracy\n\n\n\n\nType 1\nEctocervix (fully visible transformation zone)\n87.5%\n\n\nType 2\nPartially visible transformation zone\n92.3%\n\n\nType 3\nEndocervix (transformation zone not visible)\n78.5%\n\n\n\n\n\n\n\n\nPer-class Accuracy — Cervical Cancer Screening (EfficientNet-B7) / 各類別分類準確率"
  },
  {
    "objectID": "DL.html",
    "href": "DL.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Task / 任務： Classify industrial component images into 6 defect categories using a fine-tuned ResNet-18, trained on the AOI (Automated Optical Inspection) dataset. 使用 ResNet-18 對工業元件影像進行 6 類缺陷分類（AOI 自動光學檢測資料集）。\nDataset / 資料集： AOI Dataset — 2,530 training images, 10,144 test images, 6 classes (normal, void, horizontal defect, vertical defect, edge defect, particle)\nMethod / 方法： ResNet-18 (ImageNet pretrained) — frozen backbone, fine-tuned classifier head\n\n\n\n\n\n\n\nflowchart LR\n    A[\"ImageNet\\nPretrained\\nResNet-18\"] --&gt; B[\"Freeze All\\nParameters\\n(no grad)\"]\n    B --&gt; C[\"Replace fc\\nLayer → 6 classes\"]\n    C --&gt; D[\"Train\\nClassifier Only\\nAdam lr=0.001\"]\n    D --&gt; E[\"6-Class\\nDefect\\nPrediction\"]\n\n    style A fill:#e3f2fd,stroke:#2196F3\n    style B fill:#f5f5f5,stroke:#9E9E9E\n    style C fill:#fff3e0,stroke:#FF9800\n    style E fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nmodel = models.resnet18(pretrained=True)\n\n# Freeze all parameters\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final layer for 6-class output\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 6)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\nnum_epochs = 10\nbatch_size = 32\n# Input: 224×224 RGB, normalized to ImageNet mean/std\n\n\n\n\n\n\nEpoch\nTrain Loss\nVal Accuracy\n\n\n\n\n1\n0.8943\n95.26%\n\n\n2\n0.4654\n96.25%\n\n\n6\n0.2635\n96.44%\n\n\n10\n0.2381\n95.85%\n\n\n\nBest Validation Accuracy: 96.44%\n\n\n\n\n\nTraining Loss & Validation Accuracy over 10 Epochs — AOI ResNet-18 / 訓練損失與驗證準確率\n\n\n\n\n\n\n\n\n\nTask / 任務： Perform binary semantic segmentation of blood vessels in retinal fundus images using a custom U-Net architecture trained on the DRIVE dataset. 使用自製 U-Net 對 DRIVE 資料集的眼底影像進行視網膜血管二元語意分割。\nDataset / 資料集： DRIVE (Digital Retinal Images for Vessel Extraction) — 22 training, 20 test images, 512×512\nMethod / 方法： U-Net (5-level encoder-decoder with skip connections) + Focal Tversky Loss\n\n\n\n\n\n\n\n\nSample 1 — fundus image used for segmentation\n\n\n\n\n\n\n\nSample 2 — different vessel distribution pattern\n\n\n\n\n\n\n\nSample 3 — optic disc visible on right side\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n    subgraph Encoder[\"Encoder (Contracting Path)\"]\n        direction TB\n        E1[\"Conv1\\n1ch → 64\"] --&gt; P1[\"MaxPool ↓2\"]\n        P1 --&gt; E2[\"Conv2\\n64 → 128\"] --&gt; P2[\"MaxPool ↓2\"]\n        P2 --&gt; E3[\"Conv3\\n128 → 256\"] --&gt; P3[\"MaxPool ↓2\"]\n        P3 --&gt; E4[\"Conv4\\n256 → 512\"] --&gt; P4[\"MaxPool ↓2\"]\n        P4 --&gt; E5[\"Bottleneck\\n512 → 1024\"]\n    end\n\n    subgraph Decoder[\"Decoder (Expanding Path)\"]\n        direction TB\n        D1[\"UpConv\\n1024→512\\n+ skip E4\"] --&gt; C6[\"Conv6\\n1024→512\"]\n        C6 --&gt; D2[\"UpConv\\n512→256\\n+ skip E3\"] --&gt; C7[\"Conv7\\n512→256\"]\n        C7 --&gt; D3[\"UpConv\\n256→128\\n+ skip E2\"] --&gt; C8[\"Conv8\\n256→128\"]\n        C8 --&gt; D4[\"UpConv\\n128→64\\n+ skip E1\"] --&gt; C9[\"Conv9\\n128→64\"]\n        C9 --&gt; OUT[\"Conv10\\n64→1\\nSigmoid mask\"]\n    end\n\n    E5 --&gt; D1\n\n    style E5 fill:#fff3e0,stroke:#FF9800\n    style OUT fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\nclass UNet(torch.nn.Module):\n    def __init__(self, inchannel, outchannel):\n        super(UNet, self).__init__()\n        # Encoder\n        self.conv1 = Conv(inchannel, 64)\n        self.conv2 = Conv(64, 128)\n        self.conv3 = Conv(128, 256)\n        self.conv4 = Conv(256, 512)\n        self.conv5 = Conv(512, 1024)\n        self.pool  = torch.nn.MaxPool2d(2)\n        # Decoder\n        self.up1   = torch.nn.ConvTranspose2d(1024, 512, 2, 2)\n        self.conv6 = Conv(1024, 512)\n        self.up2   = torch.nn.ConvTranspose2d(512, 256, 2, 2)\n        self.conv7 = Conv(512, 256)\n        self.up3   = torch.nn.ConvTranspose2d(256, 128, 2, 2)\n        self.conv8 = Conv(256, 128)\n        self.up4   = torch.nn.ConvTranspose2d(128, 64, 2, 2)\n        self.conv9 = Conv(128, 64)\n        self.conv10 = torch.nn.Conv2d(64, outchannel, 3, 1, 1)\n\n\n\n# Focal Tversky Loss — handles class imbalance in vessel vs background\ncriterion = lambda y_pred, y_true: focal_tversky_loss(\n    y_pred, y_true, alpha=0.5, beta=0.5, gamma=0.75\n)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=5\n)\ndevice = torch.device(\"mps\")  # Apple Silicon\nnum_epochs = 100\n\n\n\nEach row shows: Original fundus image → Predicted segmentation mask → Ground truth mask 每列依序為：原始眼底影像 → 預測分割遮罩 → 真實標記遮罩\n\n\n\nSegmentation output — Original / Segmentation / Ground Truth (all 20 test images). The model learns to highlight vessel structures, though fine capillaries remain challenging. / 分割輸出：左欄原始影像、中欄預測遮罩、右欄真實標記，模型已能識別主要血管走向\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nMean IoU (mIoU)\n0.3510\n\n\nTraining epochs\n100\n\n\nInput resolution\n512 × 512\n\n\n\n\n\n\n\n\nIoU explained: intersection over union of predicted mask and ground truth / IoU 指標示意\n\n\n\n\n\n\n\n\n\nTask / 任務： Train a convolutional autoencoder to reconstruct retinal fundus images in an unsupervised manner, evaluated by Peak Signal-to-Noise Ratio (PSNR). 以無監督方式訓練卷積自動編碼器重建眼底影像，以 PSNR 作為評估指標。\nDataset / 資料集： DRIVE — 21 training, 20 test images, 512×512 RGB\nMethod / 方法： Convolutional Autoencoder (Encoder-Decoder with skip connections) + MSE Loss\n\n\n\n\n\n\n\nflowchart LR\n    subgraph Encoder[\"Encoder\"]\n        IN[\"Input\\n3ch\\n512×512\"] --&gt; C1[\"Conv1\\n3→64\"]\n        C1 --&gt; P1[\"Pool ↓2\"] --&gt; C2[\"Conv2\\n64→128\"]\n        C2 --&gt; P2[\"Pool ↓2\"] --&gt; C3[\"Conv3\\n128→256\"]\n        C3 --&gt; P3[\"Pool ↓2\"] --&gt; C4[\"Conv4\\n256→512\"]\n    end\n    subgraph Decoder[\"Decoder\"]\n        U1[\"UpConv\\n512→256\\n+skip C3\"] --&gt; D1[\"Conv5\\n512→256\"]\n        D1 --&gt; U2[\"UpConv\\n256→128\\n+skip C2\"] --&gt; D2[\"Conv6\\n256→128\"]\n        D2 --&gt; U3[\"UpConv\\n128→64\\n+skip C1\"] --&gt; D3[\"Conv7\\n128→64\"]\n        D3 --&gt; OUT[\"Conv8\\n64→3\\nReconstruction\"]\n    end\n    C4 --&gt; U1\n    style IN fill:#e8f4f8,stroke:#2196F3\n    style OUT fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\nclass AutoEncoder(nn.Module):\n    def __init__(self, inchannel=3, outchannel=3):\n        super(AutoEncoder, self).__init__()\n        # Encoder\n        self.conv1 = Conv(inchannel, 64)\n        self.conv2 = Conv(64, 128)\n        self.conv3 = Conv(128, 256)\n        self.conv4 = Conv(256, 512)\n        self.pool  = nn.MaxPool2d(2)\n        # Decoder (with skip connections)\n        self.up1   = nn.ConvTranspose2d(512, 256, 2, 2)\n        self.conv5 = Conv(512, 256)\n        self.up2   = nn.ConvTranspose2d(256, 128, 2, 2)\n        self.conv6 = Conv(256, 128)\n        self.up3   = nn.ConvTranspose2d(128, 64, 2, 2)\n        self.conv7 = Conv(128, 64)\n        self.conv8 = nn.Conv2d(64, outchannel, 3, 1, 1)\n\n\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nnum_epochs = 20\nbatch_size = 1\n# Normalization: mean=0.5, std=0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n\n\n\n\n\n\nEpoch\nTrain Loss\nTest Loss\nPSNR (dB)\n\n\n\n\n1\n0.0979\n0.1152\n16.29\n\n\n3\n0.0323\n0.0067\n27.98\n\n\n10\n0.0309\n0.0055\n29.06\n\n\n13\n0.0263\n0.0043\n30.16\n\n\n18\n0.0280\n0.0037\n30.84\n\n\n20\n0.0268\n0.0048\n29.50\n\n\n\nBest PSNR: 30.84 dB at Epoch 18\n\n\n\n\n\nTraining & Test Loss + PSNR over 20 Epochs — Convolutional Autoencoder / 訓練損失與 PSNR 曲線\n\n\n\n\n\n\n\n\n\nTask / 任務： Train a conditional GAN to generate Western blot images from two template images, learning the mapping from template patterns to realistic blot patterns. 訓練條件式 GAN，從兩張模板影像生成 Western blot 影像，學習模板圖案到真實條帶紋路的映射。\nDataset / 資料集： Western Blot Dataset — 402 template pairs + 402 target images, 64×64 grayscale\nMethod / 方法： Conditional GAN — Encoder-Decoder Generator + PatchGAN-style Discriminator\n\n\n\n\n\n\n\nflowchart TB\n    T1[\"Template 1\\n(64×64)\"] --&gt; CAT[\"Concatenate\\n(2ch input)\"]\n    T2[\"Template 2\\n(64×64)\"] --&gt; CAT\n    CAT --&gt; G[\"Generator\\nEncoder-Decoder\\n256→128→64→1\"]\n    G --&gt; FAKE[\"Generated\\nBlot Image\"]\n\n    REAL[\"Real Blot\\nImage\"] --&gt; D\n    FAKE --&gt; D[\"Discriminator\\nConv layers\\n→ Real / Fake\"]\n\n    D --&gt;|\"adversarial loss\"| G\n    D --&gt;|\"D loss\"| UPDATE_D[\"Update D\\nAdam 0.0002\"]\n    G --&gt;|\"G loss\"| UPDATE_G[\"Update G\\nAdam 0.0002\"]\n\n    style G fill:#e3f2fd,stroke:#2196F3\n    style D fill:#fce4ec,stroke:#E91E63\n    style FAKE fill:#fff3e0,stroke:#FF9800\n    style REAL fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nclass TemplateToImageGenerator(nn.Module):\n    def __init__(self):\n        super(TemplateToImageGenerator, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64), nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128), nn.ReLU(),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256), nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128), nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64), nn.ReLU(),\n            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n\n\nclass TemplateToImageDiscriminator(nn.Module):\n    def __init__(self):\n        super(TemplateToImageDiscriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(2, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Flatten(),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n\n\ng_optimizer = optim.Adam(generator.parameters(),     lr=0.0002)\nd_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\ncriterion   = nn.BCELoss()\nnum_epochs  = 200    # trained on CPU, stopped at epoch 118\nbatch_size  = 1\n\n\n\nTraining ran on CPU and was recorded up to epoch 118/200. By that point the Discriminator had begun to dominate (D Loss &lt; 0.1 in some steps), causing G Loss to climb — a classic sign the generator needs more capacity or learning rate balancing. 訓練在 CPU 上進行，記錄至第 118 個 epoch。此時判別器開始主導訓練（D Loss 低至 0.03），導致 G Loss 攀升，為典型的判別器過強問題。\n\n\n\nEpoch\nD Loss (sample)\nG Loss (sample)\n\n\n\n\n1 / step 10\n1.3715\n0.7412\n\n\n1 / step 40\n1.3699\n0.6840\n\n\n118 / step 200\n0.4921\n2.2424\n\n\n118 / step 230\n0.0263\n4.2039\n\n\n118 / step 270\n0.0683\n3.5220\n\n\n\n\n\n\n\n\nGAN Training Dynamics — Real loss values from training log (Epochs 1–118) / 真實訓練 log 數值"
  },
  {
    "objectID": "DL.html#assignments-作業",
    "href": "DL.html#assignments-作業",
    "title": "Deep Learning",
    "section": "",
    "text": "Task / 任務： Classify industrial component images into 6 defect categories using a fine-tuned ResNet-18, trained on the AOI (Automated Optical Inspection) dataset. 使用 ResNet-18 對工業元件影像進行 6 類缺陷分類（AOI 自動光學檢測資料集）。\nDataset / 資料集： AOI Dataset — 2,530 training images, 10,144 test images, 6 classes (normal, void, horizontal defect, vertical defect, edge defect, particle)\nMethod / 方法： ResNet-18 (ImageNet pretrained) — frozen backbone, fine-tuned classifier head\n\n\n\n\n\n\n\nflowchart LR\n    A[\"ImageNet\\nPretrained\\nResNet-18\"] --&gt; B[\"Freeze All\\nParameters\\n(no grad)\"]\n    B --&gt; C[\"Replace fc\\nLayer → 6 classes\"]\n    C --&gt; D[\"Train\\nClassifier Only\\nAdam lr=0.001\"]\n    D --&gt; E[\"6-Class\\nDefect\\nPrediction\"]\n\n    style A fill:#e3f2fd,stroke:#2196F3\n    style B fill:#f5f5f5,stroke:#9E9E9E\n    style C fill:#fff3e0,stroke:#FF9800\n    style E fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nmodel = models.resnet18(pretrained=True)\n\n# Freeze all parameters\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final layer for 6-class output\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 6)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\nnum_epochs = 10\nbatch_size = 32\n# Input: 224×224 RGB, normalized to ImageNet mean/std\n\n\n\n\n\n\nEpoch\nTrain Loss\nVal Accuracy\n\n\n\n\n1\n0.8943\n95.26%\n\n\n2\n0.4654\n96.25%\n\n\n6\n0.2635\n96.44%\n\n\n10\n0.2381\n95.85%\n\n\n\nBest Validation Accuracy: 96.44%\n\n\n\n\n\nTraining Loss & Validation Accuracy over 10 Epochs — AOI ResNet-18 / 訓練損失與驗證準確率\n\n\n\n\n\n\n\n\n\nTask / 任務： Perform binary semantic segmentation of blood vessels in retinal fundus images using a custom U-Net architecture trained on the DRIVE dataset. 使用自製 U-Net 對 DRIVE 資料集的眼底影像進行視網膜血管二元語意分割。\nDataset / 資料集： DRIVE (Digital Retinal Images for Vessel Extraction) — 22 training, 20 test images, 512×512\nMethod / 方法： U-Net (5-level encoder-decoder with skip connections) + Focal Tversky Loss\n\n\n\n\n\n\n\n\nSample 1 — fundus image used for segmentation\n\n\n\n\n\n\n\nSample 2 — different vessel distribution pattern\n\n\n\n\n\n\n\nSample 3 — optic disc visible on right side\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n    subgraph Encoder[\"Encoder (Contracting Path)\"]\n        direction TB\n        E1[\"Conv1\\n1ch → 64\"] --&gt; P1[\"MaxPool ↓2\"]\n        P1 --&gt; E2[\"Conv2\\n64 → 128\"] --&gt; P2[\"MaxPool ↓2\"]\n        P2 --&gt; E3[\"Conv3\\n128 → 256\"] --&gt; P3[\"MaxPool ↓2\"]\n        P3 --&gt; E4[\"Conv4\\n256 → 512\"] --&gt; P4[\"MaxPool ↓2\"]\n        P4 --&gt; E5[\"Bottleneck\\n512 → 1024\"]\n    end\n\n    subgraph Decoder[\"Decoder (Expanding Path)\"]\n        direction TB\n        D1[\"UpConv\\n1024→512\\n+ skip E4\"] --&gt; C6[\"Conv6\\n1024→512\"]\n        C6 --&gt; D2[\"UpConv\\n512→256\\n+ skip E3\"] --&gt; C7[\"Conv7\\n512→256\"]\n        C7 --&gt; D3[\"UpConv\\n256→128\\n+ skip E2\"] --&gt; C8[\"Conv8\\n256→128\"]\n        C8 --&gt; D4[\"UpConv\\n128→64\\n+ skip E1\"] --&gt; C9[\"Conv9\\n128→64\"]\n        C9 --&gt; OUT[\"Conv10\\n64→1\\nSigmoid mask\"]\n    end\n\n    E5 --&gt; D1\n\n    style E5 fill:#fff3e0,stroke:#FF9800\n    style OUT fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\nclass UNet(torch.nn.Module):\n    def __init__(self, inchannel, outchannel):\n        super(UNet, self).__init__()\n        # Encoder\n        self.conv1 = Conv(inchannel, 64)\n        self.conv2 = Conv(64, 128)\n        self.conv3 = Conv(128, 256)\n        self.conv4 = Conv(256, 512)\n        self.conv5 = Conv(512, 1024)\n        self.pool  = torch.nn.MaxPool2d(2)\n        # Decoder\n        self.up1   = torch.nn.ConvTranspose2d(1024, 512, 2, 2)\n        self.conv6 = Conv(1024, 512)\n        self.up2   = torch.nn.ConvTranspose2d(512, 256, 2, 2)\n        self.conv7 = Conv(512, 256)\n        self.up3   = torch.nn.ConvTranspose2d(256, 128, 2, 2)\n        self.conv8 = Conv(256, 128)\n        self.up4   = torch.nn.ConvTranspose2d(128, 64, 2, 2)\n        self.conv9 = Conv(128, 64)\n        self.conv10 = torch.nn.Conv2d(64, outchannel, 3, 1, 1)\n\n\n\n# Focal Tversky Loss — handles class imbalance in vessel vs background\ncriterion = lambda y_pred, y_true: focal_tversky_loss(\n    y_pred, y_true, alpha=0.5, beta=0.5, gamma=0.75\n)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=5\n)\ndevice = torch.device(\"mps\")  # Apple Silicon\nnum_epochs = 100\n\n\n\nEach row shows: Original fundus image → Predicted segmentation mask → Ground truth mask 每列依序為：原始眼底影像 → 預測分割遮罩 → 真實標記遮罩\n\n\n\nSegmentation output — Original / Segmentation / Ground Truth (all 20 test images). The model learns to highlight vessel structures, though fine capillaries remain challenging. / 分割輸出：左欄原始影像、中欄預測遮罩、右欄真實標記，模型已能識別主要血管走向\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nMean IoU (mIoU)\n0.3510\n\n\nTraining epochs\n100\n\n\nInput resolution\n512 × 512\n\n\n\n\n\n\n\n\nIoU explained: intersection over union of predicted mask and ground truth / IoU 指標示意\n\n\n\n\n\n\n\n\n\nTask / 任務： Train a convolutional autoencoder to reconstruct retinal fundus images in an unsupervised manner, evaluated by Peak Signal-to-Noise Ratio (PSNR). 以無監督方式訓練卷積自動編碼器重建眼底影像，以 PSNR 作為評估指標。\nDataset / 資料集： DRIVE — 21 training, 20 test images, 512×512 RGB\nMethod / 方法： Convolutional Autoencoder (Encoder-Decoder with skip connections) + MSE Loss\n\n\n\n\n\n\n\nflowchart LR\n    subgraph Encoder[\"Encoder\"]\n        IN[\"Input\\n3ch\\n512×512\"] --&gt; C1[\"Conv1\\n3→64\"]\n        C1 --&gt; P1[\"Pool ↓2\"] --&gt; C2[\"Conv2\\n64→128\"]\n        C2 --&gt; P2[\"Pool ↓2\"] --&gt; C3[\"Conv3\\n128→256\"]\n        C3 --&gt; P3[\"Pool ↓2\"] --&gt; C4[\"Conv4\\n256→512\"]\n    end\n    subgraph Decoder[\"Decoder\"]\n        U1[\"UpConv\\n512→256\\n+skip C3\"] --&gt; D1[\"Conv5\\n512→256\"]\n        D1 --&gt; U2[\"UpConv\\n256→128\\n+skip C2\"] --&gt; D2[\"Conv6\\n256→128\"]\n        D2 --&gt; U3[\"UpConv\\n128→64\\n+skip C1\"] --&gt; D3[\"Conv7\\n128→64\"]\n        D3 --&gt; OUT[\"Conv8\\n64→3\\nReconstruction\"]\n    end\n    C4 --&gt; U1\n    style IN fill:#e8f4f8,stroke:#2196F3\n    style OUT fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\nclass AutoEncoder(nn.Module):\n    def __init__(self, inchannel=3, outchannel=3):\n        super(AutoEncoder, self).__init__()\n        # Encoder\n        self.conv1 = Conv(inchannel, 64)\n        self.conv2 = Conv(64, 128)\n        self.conv3 = Conv(128, 256)\n        self.conv4 = Conv(256, 512)\n        self.pool  = nn.MaxPool2d(2)\n        # Decoder (with skip connections)\n        self.up1   = nn.ConvTranspose2d(512, 256, 2, 2)\n        self.conv5 = Conv(512, 256)\n        self.up2   = nn.ConvTranspose2d(256, 128, 2, 2)\n        self.conv6 = Conv(256, 128)\n        self.up3   = nn.ConvTranspose2d(128, 64, 2, 2)\n        self.conv7 = Conv(128, 64)\n        self.conv8 = nn.Conv2d(64, outchannel, 3, 1, 1)\n\n\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nnum_epochs = 20\nbatch_size = 1\n# Normalization: mean=0.5, std=0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n\n\n\n\n\n\nEpoch\nTrain Loss\nTest Loss\nPSNR (dB)\n\n\n\n\n1\n0.0979\n0.1152\n16.29\n\n\n3\n0.0323\n0.0067\n27.98\n\n\n10\n0.0309\n0.0055\n29.06\n\n\n13\n0.0263\n0.0043\n30.16\n\n\n18\n0.0280\n0.0037\n30.84\n\n\n20\n0.0268\n0.0048\n29.50\n\n\n\nBest PSNR: 30.84 dB at Epoch 18\n\n\n\n\n\nTraining & Test Loss + PSNR over 20 Epochs — Convolutional Autoencoder / 訓練損失與 PSNR 曲線\n\n\n\n\n\n\n\n\n\nTask / 任務： Train a conditional GAN to generate Western blot images from two template images, learning the mapping from template patterns to realistic blot patterns. 訓練條件式 GAN，從兩張模板影像生成 Western blot 影像，學習模板圖案到真實條帶紋路的映射。\nDataset / 資料集： Western Blot Dataset — 402 template pairs + 402 target images, 64×64 grayscale\nMethod / 方法： Conditional GAN — Encoder-Decoder Generator + PatchGAN-style Discriminator\n\n\n\n\n\n\n\nflowchart TB\n    T1[\"Template 1\\n(64×64)\"] --&gt; CAT[\"Concatenate\\n(2ch input)\"]\n    T2[\"Template 2\\n(64×64)\"] --&gt; CAT\n    CAT --&gt; G[\"Generator\\nEncoder-Decoder\\n256→128→64→1\"]\n    G --&gt; FAKE[\"Generated\\nBlot Image\"]\n\n    REAL[\"Real Blot\\nImage\"] --&gt; D\n    FAKE --&gt; D[\"Discriminator\\nConv layers\\n→ Real / Fake\"]\n\n    D --&gt;|\"adversarial loss\"| G\n    D --&gt;|\"D loss\"| UPDATE_D[\"Update D\\nAdam 0.0002\"]\n    G --&gt;|\"G loss\"| UPDATE_G[\"Update G\\nAdam 0.0002\"]\n\n    style G fill:#e3f2fd,stroke:#2196F3\n    style D fill:#fce4ec,stroke:#E91E63\n    style FAKE fill:#fff3e0,stroke:#FF9800\n    style REAL fill:#e8f8e8,stroke:#4CAF50\n\n\n\n\n\n\n\n\n\nclass TemplateToImageGenerator(nn.Module):\n    def __init__(self):\n        super(TemplateToImageGenerator, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64), nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128), nn.ReLU(),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256), nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128), nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64), nn.ReLU(),\n            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n\n\nclass TemplateToImageDiscriminator(nn.Module):\n    def __init__(self):\n        super(TemplateToImageDiscriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(2, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Flatten(),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n\n\ng_optimizer = optim.Adam(generator.parameters(),     lr=0.0002)\nd_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\ncriterion   = nn.BCELoss()\nnum_epochs  = 200    # trained on CPU, stopped at epoch 118\nbatch_size  = 1\n\n\n\nTraining ran on CPU and was recorded up to epoch 118/200. By that point the Discriminator had begun to dominate (D Loss &lt; 0.1 in some steps), causing G Loss to climb — a classic sign the generator needs more capacity or learning rate balancing. 訓練在 CPU 上進行，記錄至第 118 個 epoch。此時判別器開始主導訓練（D Loss 低至 0.03），導致 G Loss 攀升，為典型的判別器過強問題。\n\n\n\nEpoch\nD Loss (sample)\nG Loss (sample)\n\n\n\n\n1 / step 10\n1.3715\n0.7412\n\n\n1 / step 40\n1.3699\n0.6840\n\n\n118 / step 200\n0.4921\n2.2424\n\n\n118 / step 230\n0.0263\n4.2039\n\n\n118 / step 270\n0.0683\n3.5220\n\n\n\n\n\n\n\n\nGAN Training Dynamics — Real loss values from training log (Epochs 1–118) / 真實訓練 log 數值"
  }
]